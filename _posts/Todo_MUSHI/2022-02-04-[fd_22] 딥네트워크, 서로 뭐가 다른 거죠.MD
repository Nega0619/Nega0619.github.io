해당 포스팅은, 아이펠 Fundamental 22번 노드를 학습하고 작성한 기록물 입니다.



< 목차 >

1. pre-trainded 모델이란?

2. AlexNet

3. vGG-16

- 



# 1. pre-trained 모델이란?



이미 배워왔듯, 신경망을 깊이 쌓는다고 해서 무조건 성능이 좋아지는 것은 아닙니다. 신경망을 깊게 쌓을 수록 overfitting문제와 학습될 parameter들이 기하급수적으로 증가하는 문제, 이와 더불어 연산속도와 학습속도에 오래걸리는 등 다양한 문제가 발생합니다.



그렇기 때문에, 연구자들이 더 좋은 성능을 내는 딥러닝 신경망을 만들기 위해 다양한 방법을 시도하였고, 많은 네트워크들이 탄생했습니다. 다음은 그 중 몇가지 예시인 pre-trained 모델 리스트입니다. 

![content img](../images/pages/F-22-2.max-800x600_hpMcSFb.png)

[Pre-trained 모델의 구조]



- 여기서 더 볼수있습니다 : https://github.com/tensorflow/models/tree/master/research/slim



# 2. AlexNet

2012년 Image Classification Task에서 Geoffrey Hinton 교수님이 이끄는 토론토 대학의 SuperVision팀이 오류율 16%로 1등을 달성합니다. 작년의 우승자는 오류율 26%, 제작년은 28%였으니 엄청난 차이를 보여준것입니다. superVision팀이 사용한 모델이 AlexNet입니다.



![img](../images/pages/99FEB93C5C80B5192E)



## AlexNet 구조

기본 구조는 [LeNet-5](https://bskyvision.com/418)와 크게 다르지 않습니다. 2개의  GPU로 병렬연산을 수행하기 위해 병렬 구조로 설계되었다는 점이 가장 큰 변화입니다.



총 8개의 레이어로 이루어져 있으며, 5개는 Conv 레이어, 3개는 FC 레이어로 구성되어 있습니다. (맨 왼쪽은 input data입니다.)

2, 4, 5번째 컨볼루션 레이어들은 전 단계의 feature map과 연결되어 있지만, 3번째 레이어에서는 병렬처리로 나뉜 두 단계의 feature맵과 모두 연결되어 있는 것이 특징입니다. 



더 자세한 내용은 다음 링크에 설명이 되어있습니다.

- 링크





















-----------

용어 검색

- overlapping max pooling
- local response normalization





------

###### 출처

- AIFFEL LMS 

  문제시 연락 부탁드립니다. :)

  

###### 참고사이트

- https://bskyvision.com/421