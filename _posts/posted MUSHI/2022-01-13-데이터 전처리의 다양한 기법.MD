인공지능에는 다양한 데이터 처리의 다양한 기법이 있습니다.

오늘은 다양한 데이터 전처리의 기법에 대해 알아보았고, 각각의 내용을 정리해 보았습니다. 그리고 그에 대한 내용을 링크에 남겼습니다.



# 데이터 전처리 기법



## 결측치

결측치란, 입력이 누락된 값입니다. 보통 제거하거나 대체하여 처리를 합니다.

[데이터 전처리 ) 결측치 처리 방법]: https://wannabe-professional-programmer.tistory.com/38



## 중복된 데이터

말 그대로, 중복된 데이터입니다. 혹시 데이터의 특성상 같은 행에서 모든 데이터가 유일해야 한다면, 중복된 데이터를 제거하여 처리합니다.

[데이터 전처리 ) 중복된 데이터 처리 방법]: http://



## 이상치 outlier

대부분의 값의 범위에서 벗어나 극단적으로 크거나 작은 값. 이상치를 처리하는 방법은 z-score, modified z-score method, iqr method가 있다.

[데이터 전처리 ) 이상치 처리 방법]: https://wannabe-professional-programmer.tistory.com/42



## 정규화 Normalization



[데이터 전처리 ) 정규화 처리 방법]: 



## 원-핫-인코딩 One-Hot-Encoding



[데이터 전처리 ) 원-핫-인코딩 처리 방법]: http://



## 구간화 Binning



[데이터 전처리 ) 구간화 처리 방법]: http://



## 그 밖의 기법



### 로그변환

2019년 kaggle에서 진행한 캐글 코리아와 함께하는 2nd ML대회 - House Price Prediction에서 train데이터의 분포를 살펴보면 다음과 같습니다.

![image-20220118115250139](../assets/img/posts/image-20220118115250139.png)

...생략

![image-20220118115432937](../assets/img/posts/image-20220118115432937.png)

위 그래프 중에서 `bedrooms`, `sqft_living`, `sqft_lot`, `sqft_above`, `sqft_basement`, `sqft_living15`, `sqft_lot15` 변수가 한쪽으로 치우친 경향을 보입니다.



이렇게 한쪽으로 치우친 분포의 경우, 로그 변환(log_scaling)을 통해 데이터 분포를 정규분포에 가깝게 만들어 주면 좋습니다.



```python
skew_columns = ['bedrooms', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', 'sqft_lot15', 'sqft_living15']

for c in skew_columns:
    data[c] = np.log1p(data[c].values)
```

위 코드는 로그 변환을 한 코드입니다. `numpy.log1p()` 함수는 입력 배열의 각 요소에 자연로그 log(1 + x)처리해 주는 함수입니다.



![image-20220118114752191](../assets/img/posts/image-20220118114752191.png)

![image-20220118115045968](../assets/img/posts/image-20220118115045968.png)

이전보다 치우침이 줄어든 분포를 확인할 수있습니다.



로그 변환시 치우침이 줄어드는 이유는 다음과 같습니다.

1. 0<x<1 범위에서 기울기는 매우 가파릅니다. 그래서 x의 범위는 0-1로 매우 작은 반면 y는 (−∞,0)로 매우 발산하는 형태입니다.
2. 따라서, 0에 치우친 값들을 로그 변환하면 값이 넓은 범위로 펼칠 수 있는 특징을 갖게 됩니다.
3. 반면 x값이 1을 넘어가면 y의 기울기는 급격히 작아집니다. 즉, 큰 x 값들에 대해 y값이 크게 차이나지 않게되며 넓은 범위의 x값은 작은 y값에 모이게 됩니다.

























