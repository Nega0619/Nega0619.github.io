I"F<p>오늘은 아이펠 29번 fundamental 노드를 읽고 공부한 것을 작성해 보았습니다.</p>

<blockquote>
  <p>깃허브 : https://github.com/Nega0619/Aiffel_Fundamental_nodes/blob/main/%5Bfd_29%5D%20Introduction%20to%20the%20recommendation%20system%20using%20scikit-learn.ipynb</p>
</blockquote>

<h6 id="목차">목차</h6>

<ul>
  <li>추천시스템이란?</li>
  <li>유사도 계산</li>
  <li>추천 시스템 종류
    <ul>
      <li>콘텐츠 기반 필터링</li>
      <li>협업 필터링
        <ul>
          <li>사용자 기반</li>
          <li>아이템 기반</li>
          <li>잠재요인 협업 필터링</li>
        </ul>
      </li>
      <li>실제 추천 시스템</li>
    </ul>
  </li>
</ul>

<h1 id="1-추천-시스템이란">1. 추천 시스템이란?</h1>

<blockquote>
  <p>사용자와 관련한 아이템을 추천해주는 것</p>
</blockquote>

<p>이라고 한마디로 정의할 수 있습니다.</p>

<p>영화 추천 시스템을 예로 설명해보겠습니다.</p>

<p>실제 추천 시스템에서는 영화를 아래 사진처럼 좌표평면에 표현합니다.</p>

<p>수식을 이용해 정교하게 그리지만, 대략적으로 그리면 다음과 같습니다.</p>

<p><img src="../assets/img/posts/image-20220221104115455.png" alt="image-20220221104115455" /></p>

<p>이렇게 놓고 보면 거리가 가까운 영화들은 장르가 비슷하다고 생각할 수 있으며, 사용자의 선호도가 어디에 위치하느냐에 따라 사용자에게 맞는 영화를 추천해 줄 수 있습니다.</p>

<p>이러한 추천은 사용자가 이용한 콘텐츠를 기반으로 추천해 주는 방식입니다. 하지만 만약 뉴비 사용자가 나타났다면 어떻게 추천을 해줄까요?</p>

<p>보통은 취향에 대한 정보를 받도록 설문조사가 배치되어있지만 전부 다 스킵하고 정말 인적사항만 아는 사용자의 경우가 있습니다. 이 경우, 뉴비 사용자의 인적사항과 기존 회원들의 인적사항을 분석하여 유사도를 측정하고, 뉴비 사용자에게 유사한 인적사항을 가진 사용자의 선호를 추천해주게 됩니다.</p>

<p>간단한 추천 로직이며, 이를 통해 두가지를 꼭 기억해야 합니다.</p>

<ol>
  <li>
    <p>범주형 데이터를 다룬다.</p>

    <p>이산적, 혹은 범주형이라고 합니다. 액션 / 로맨스 / 호러 등 카테고리가 나뉜 형태의 데이터입니다.</p>
  </li>
  <li>
    <p>(숫자 벡터로 변환한 후) 유사도를 계산한다.</p>

    <p>범주형 데이터를 좌표에 나타내기 위하여 숫자로 이루어진 벡터로 변환합니다.(numerical vector) 그리고 그 거리를 계산해 유사도를 측정합니다.</p>
  </li>
</ol>

<h1 id="2-코사인-유사도">2. 코사인 유사도</h1>

<p>가장 유명한 유사도를 계산하는 방법입니다. 코사인 유사도는 두 벡터간의 코사인값을 계산하여 유사도를 측정하게됩니다.</p>

<p>코사인 유사도는 두 벡터가 방향이 이루는 각도에 코사인을 취해 구합니다.</p>

<p><img src="../assets/img/posts/image-20220221105201542.png" alt="image-20220221105201542" /></p>

<p>위 그림은 두 벡터가 이루는 각도에 따른 유사도입니다. 1에 가까울 수록 유사도가 높다고 할 수 있습니다. 수식은 다음과 같습니다.</p>

<p><img src="../assets/img/posts/image-20220221105248414.png" alt="image-20220221105248414" /></p>

<h3 id="numpy를-이용한-코사인-유사도">numpy를 이용한 코사인 유사도</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">dot</span>
<span class="kn">from</span> <span class="nn">numpy.linalg</span> <span class="kn">import</span> <span class="n">norm</span>
<span class="k">def</span> <span class="nf">cos_sim</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">):</span>
	<span class="k">return</span> <span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">norm</span><span class="p">(</span><span class="n">A</span><span class="p">)</span><span class="o">*</span><span class="n">norm</span><span class="p">(</span><span class="n">B</span><span class="p">))</span>
</code></pre></div></div>

<h3 id="사이킷-런을-활용한-코사인-유사도">사이킷 런을 활용한 코사인 유사도</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">t2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">cosine_similarity</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span><span class="n">t2</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="다른-방법의-유사도-측정방법">다른 방법의 유사도 측정방법</h3>

<p>유클리드 거리 / 자카드 유사도 / 피어슨 상관계수 등의 방법이 있습니다.</p>

<h1 id="3-추천-시스템의-종류">3. 추천 시스템의 종류</h1>

<ul>
  <li>
    <p>콘텐츠 기반 필터링 (Content Based Filtering)</p>
  </li>
  <li>
    <p>협업 기반 필터링 (Collaborative Filtering</p>

    <ul>
      <li>사용자 기반</li>
      <li>아이템 기반</li>
      <li>잠재요인 협업 필터링 (latent factor collaborative filtering) → 행렬 인수분해(matrix factorization)</li>
    </ul>
  </li>
  <li>
    <p>DeepLearning 적용</p>
  </li>
  <li>
    <p>Hybrid방식</p>

    <p>여러 방법을 결합한 방식</p>
  </li>
</ul>

<h2 id="3-1-콘텐츠-기반-필터링-방식">3-1. 콘텐츠 기반 필터링 방식</h2>

<p>콘텐츠 기반은 오직 콘텐츠의 내용만을 비교해 추천하는 방식입니다.</p>

<p>아까 예를 들었던 영화로 말하자면, 사람들이 영화를 볼때 고려하는 점은 다음과 같습니다. 장르, 배우, 감독 등의 정보. 이러한 요소들을 영화의 <strong>특성(Feature)</strong>이라고 하고 이 특성을 바탕으로 콘텐츠의 유사도를 측정하게 됩니다.</p>

<ul>
  <li>코드</li>
</ul>

<p><strong>해당 예제는 CODE HEROKU의 <a href="http://www.codeheroku.com/post.html?name=Building a Movie Recommendation Engine in Python using Scikit-Learn">‘Building a Movie Recemmendation Engine in Python using Scikit-Learn’</a> 을 바탕으로 제작되었습니다.</strong></p>

<blockquote>
  <p>전체코드는 깃허브를 참고하시고, 블로그에는 새로 배운 것 위주로 작성하였습니다.</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>
</code></pre></div></div>

<ul>
  <li>
    <p>os.getcwd() : 현재 파일이 실행되고 있는 working directory 출력</p>
  </li>
  <li>
    <p>scikit-learn.CountVectorize() : 단순하게 등장 횟수를 세어 숫자 벡터로 만들어줌.</p>

    <ul>
      <li>
        <p>out : CSR(Compressed Sparse Row) Matrix</p>

        <p>CSR Matrix란?</p>

        <p>Sparse한 matrix에서 0이 아닌 데이터로 채워지는 데이터 값과 좌표 정보로만으로 구성하여 메모리 사용량을 최소화하고 Sparse한 matrix와 동일한 행렬을 표현할 수 있도록 하는 데이터 구조</p>
      </li>
    </ul>
  </li>
  <li>
    <p>CountVectorize().fit_transform(pandas.dataframe)</p>

    <ul>
      <li>데이터에 맞춘 다음 변환합니다.</li>
    </ul>
  </li>
  <li>
    <p>cosine_similarity() : 코사인 유사도를 구하는 메소드</p>

    <ul>
      <li>in : CSR Matrix</li>
    </ul>
  </li>
</ul>

<h2 id="3-2-협업-필터링-방식">3-2. 협업 필터링 방식</h2>

<p>과거의 사용자 행동 양식(User Behavior) 데이터를 기반으로 추천하는 방식으로, 잠재요인 기법을 활용하여 행동 양식을 데이터로 나타냄</p>

<h3 id="기본원리">기본원리</h3>

<p><img src="../assets/img/posts/image-20220221144819086.png" alt="image-20220221144819086" /></p>

<p>다음과 같은 테이블이 있다고 생각해봅시다. timestamp는 사용자가 평점을 매긴 시간입니다. 위 데이터를 사용자와 아이템간의 interaction matrix로 변환해봅시다. 그리고 해당 행렬의 데이터로 평점을 넣으면 아래와 같은 형식이 됩니다. 이를 평점행렬이라고 부르기도 합니다.</p>

<p><img src="../assets/img/posts/image-20220221144944827.png" alt="image-20220221144944827" /></p>

<p>이러한 행렬은 굉장히 희소(sparse)한 행렬이 됩니다.</p>

<p>평점 행렬로 변환 후, 평점 행렬의 유사도를 계산하여 추천하는 방식 : 사용자기반, 아이템 기반 방식</p>

<p>평점행렬을 분해하여 더 많은 정보를 고려하는 방식 : 잠재요인 필터링</p>

<p>정리하자면 다음과 같습니다.</p>

<ul>
  <li>협업 필터링의 종류
    <ul>
      <li>사용자 기반
        <ul>
          <li>유사도 계산방식</li>
        </ul>
      </li>
      <li>아이템 기반
        <ul>
          <li>유사도 계산방식</li>
        </ul>
      </li>
      <li>잠재요인 기반
        <ul>
          <li>행렬인수분해 방식</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="사용자기반">사용자기반</h3>

<blockquote>
  <p>당신과 비슷한 고객들이 다음 상품을 구매했습니다.</p>
</blockquote>

<p>위 글을 시스템으로 만든 것이 사용자 기반 추천시스템입니다.</p>

<p><img src="../assets/img/posts/image-20220221154853846.png" alt="image-20220221154853846" /></p>

<p>user 4가 아이템 1을 구매하고, user 4와 가장 유사한 user 2는 아이템 1-4까지 위와 같은 평점을 남겼다고 합시다. 이 경우, user2가 선호한 제품인 item 3을 4에게 추천해주는 방식입니다.</p>

<h3 id="아이템기반">아이템기반</h3>

<blockquote>
  <p>이 상품을 선택한 다른 고객들은 다음 상품을 구매했습니다.</p>
</blockquote>

<p>위 말을 시스템으로 만든 것이 아이템 기반 추천 시스템입니다. 일반적으로 사용자 기반보다는 아이템 기반 방식이 정확도가 높다고 합니다.</p>

<p><img src="../assets/img/posts/image-20220221155923256.png" alt="image-20220221155923256" /></p>

<p>user2가 위와 같은 선호도를 가졌다할 때, 아이템 1의 선호도가 가장 높습니다.</p>

<p>그리고 아이템 1의 선호도는 다음과 같습니다.</p>

<p><img src="../assets/img/posts/image-20220221155952136.png" alt="image-20220221155952136" /></p>

<p>아이템 2을 좋아한 사람은 user4이므로 user4에게 user2가 좋아한 상품인 3을 추천해줍니다.</p>

<p><img src="../assets/img/posts/image-20220221160008483.png" alt="image-20220221160008483" /></p>

<h3 id="잠재요인-협업-필터링-기반">잠재요인 협업 필터링 기반</h3>

<p>평점행렬을 행렬 인수분해(matrix factorization)를 통해 잠재요인(latent factor)을 분석</p>

<p>행렬 인수분해 종류</p>

<ul>
  <li>SVD(Singular Vector Decomposition)</li>
  <li>ALS(Alternating Least Squares)</li>
  <li>NMF(Non-Negative Factorization)</li>
</ul>

<h4 id="svd-singular-vector-decomposition">SVD Singular Vector Decomposition</h4>

<p>가장 많이 사용됨, 우리말로는 특잇값 분해</p>

<p>M*N 형태의 행렬 A를 다음과 같은 형태로 분해하여 나타냄</p>

<p><img src="../assets/img/posts/image-20220221171929948.png" alt="image-20220221171929948" /></p>

<ul>
  <li>
    <p>구현 메소드 : https://numpy.org/doc/stable/reference/generated/numpy.linalg.svd.html</p>
  </li>
  <li>코드
    <ul>
      <li>np.diag(Sigma) : 대각선을 추출하거나 대각선 배열을 구성합니다.</li>
      <li>np.dot(np.dot(U, Sigma_mat), VT) : 두 배열간의 내적</li>
    </ul>
  </li>
  <li>
    <p>참고 링크</p>

    <ul>
      <li>
        <p><a href="https://angeloyeo.github.io/2019/08/01/SVD.html">특잇값분해</a></p>
      </li>
      <li>
        <p>[<a href="https://darkpgmr.tistory.com/106">선형대수학 #4] 특이값 분해(Singular Value Decomposition, SVD)의 활용</a></p>
      </li>
    </ul>
  </li>
</ul>

<h4 id="truncated-svd--lsa-latent-sementic-analysis">Truncated SVD = LSA Latent Sementic Analysis</h4>

<p>우리말로 번역하면 잘린 SVD, 다른 말로는 LSA(Latent semantic analysis), 잠재 의미 분석 이라고 합니다.</p>

<p>Truncated SVD를 이용해 분해한 뒤, 복원하면 SVD처럼 완벽히 나오지않습니다. 왜냐하면 Truncated SVD가 차원을 축소한 다음 행렬을 분해하기 때문입니다.</p>

<p>SVD(특이값 분해)를 평가행렬에 적용해 잠재요인을 분석하는 것을 도식화하면 사진과 같습니다.</p>

<p><img src="../assets/img/posts/image-20220221174558265.png" alt="image-20220221174558265" /></p>

<p>표기법</p>

<ul>
  <li>R: 사용자와 아이템 사이의 행렬</li>
  <li>P: 사용자와 잠재요인 사이의 행렬</li>
  <li>Q: 아이템과 잠재요인 사이의 행렬 —&gt; 전치 행렬 형태로 나타냄</li>
</ul>

<p><img src="../assets/img/posts/image-20220221174851001.png" alt="image-20220221174851001" /></p>

<p>사용자가 아이템에 대한 평점을 매기는 요인으로 많은 항목들이 있습니다. 그리고 평점을 매기는 것은 매우 주관적입니다. 그렇기 때문에, 사용자가 평점을 매기는 요인을 잠재요인으로 취급한 뒤, SVD 기법을 이용해 분해하고, 다시 합치는 방법으로 영화에 평점을 매긴 이유를 벡터화하고 이를 기반으로 추천합니다. 이 기법은 넷플릭스, 왓챠, 유튜브와 같은 기업에서 효과를 입증해냈고 이후 많은 기업들도 채택하였다고 합니다.</p>

<p>이렇게 협업 필터링을 이용하면 사용자가 아이템에 대해 평점을 매긴 평점행렬을 인수분해(Matrix Factorization)를 통해 잠재요인을 분석한 뒤 유사도를 계산할 수도 있으며 사용자의 평점도 예측할 수 있습니다. 특히 잠재요인을 고려해 행렬을 인수분해하면 파라미터수는 감소하게 됩니다.</p>

<p>구현 메소드 : https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html</p>

<h2 id="3-3-실제-추천-시스템">3-3. 실제 추천 시스템</h2>

<p>오늘 작성한 내용들은 추천 시스템에 기본이 되는 요소입니다. 실제로 대기업에서는 더 많은 것을 추천에 고려합니다.</p>

<p>사용자의 구매여부, 평점데이터는 기본이고 얼마나 오랜 시간 시청(혹은 사이트에 머물렀는지)했는지, 어떤 사이트에서 유입되었는지, 시청 후 구매로 이어지기까지의 시간 등 행동 족적을 다 분석합니다. 이를 전문 용어로 <strong>Digital Footprint(디지털 발자국), Digital Shadow(디지털 그림자)</strong>라고 합니다.</p>

<p>이중 가장 중요한 지표가 **클릭룰( CTR , Click Through Rate) **입니다.</p>

<ul>
  <li>참고: <a href="https://support.google.com/google-ads/answer/2615875?hl=en">Clickthrough rate (CTR): Definition</a></li>
</ul>

<p>어떻게든 다양한 데이터들을 모아 추천을 한 뒤, 적절한 추천이었는지 아니었는지를 평가하는 것 또한 중요한 일입니다. 추천한 제품이 구매 혹은 시청으로 이루어졌는지를 통해 추천의 성공여부를 평가하기도 하고, 모델 단계에서 평가하기도 합니다.</p>

<p>추천시스템은 매우 큰 시스템입니다. 데이터를 기반으로 고객에게 적절한 제품 혹은 콘텐츠를 추천하고, 이것이 구매 , 결제로 이루어 지는 것은 매출과 직결되는 문제기도 합니다. 좋은 추천 시스템을 만들기 위해서는, 어떤 데이터를 사용할지 매우 고민을 해야합니다. 어떤 데이터가 사용자와 연관성이 있을지, 구매와 직결되는 각종 데이터는 무엇인지 고려하고 수집, 정렬(sorting)하여 다시 순위(ranking)를 매긴 다음 평가하는 작업을 반복하며 적합한 데이터와 추천 시스템이 만들어냅니다.</p>

<blockquote>
  <p>추천시스템이 머신러닝이 적용될 수도 있는거지 머신러닝안에 추천시스템이 있는것은 아닙니다.</p>
</blockquote>

<hr />

<h6 id="출처">출처</h6>

<ul>
  <li>
    <p>AIFFEL LMS</p>

    <p>문제시 연락 부탁드립니다. :)</p>
  </li>
  <li>
    <p>5</p>
  </li>
</ul>
:ET