<p>해당 포스팅은, 아이펠 Fundamental 22번 노드를 학습하고 작성한 기록물 입니다.</p>

<p>&lt; 목차 &gt;</p>

<ol>
  <li>
    <p>pre-trainded 모델이란?</p>
  </li>
  <li>
    <p>AlexNet</p>
  </li>
  <li>
    <p>vGG-16</p>
  </li>
</ol>

<ul>
  <li></li>
</ul>

<h1 id="1-pre-trained-모델이란">1. pre-trained 모델이란?</h1>

<p>이미 배워왔듯, 신경망을 깊이 쌓는다고 해서 무조건 성능이 좋아지는 것은 아닙니다. 신경망을 깊게 쌓을 수록 overfitting문제와 학습될 parameter들이 기하급수적으로 증가하는 문제, 이와 더불어 연산속도와 학습속도에 오래걸리는 등 다양한 문제가 발생합니다.</p>

<p>그렇기 때문에, 연구자들이 더 좋은 성능을 내는 딥러닝 신경망을 만들기 위해 다양한 방법을 시도하였고, 많은 네트워크들이 탄생했습니다. 다음은 그 중 몇가지 예시인 pre-trained 모델 리스트입니다.</p>

<p><img src="../images/pages/F-22-2.max-800x600_hpMcSFb.png" alt="content img" /></p>

<p>[Pre-trained 모델의 구조]</p>

<ul>
  <li>여기서 더 볼수있습니다 : https://github.com/tensorflow/models/tree/master/research/slim</li>
</ul>

<h1 id="2-alexnet">2. AlexNet</h1>

<p>2012년 Image Classification Task에서 Geoffrey Hinton 교수님이 이끄는 토론토 대학의 SuperVision팀이 오류율 16%로 1등을 달성합니다. 작년의 우승자는 오류율 26%, 제작년은 28%였으니 엄청난 차이를 보여준것입니다. superVision팀이 사용한 모델이 AlexNet입니다.</p>

<p><img src="../images/pages/99FEB93C5C80B5192E" alt="img" /></p>

<h2 id="alexnet-구조">AlexNet 구조</h2>

<p>기본 구조는 <a href="https://bskyvision.com/418">LeNet-5</a>와 크게 다르지 않습니다. 2개의  GPU로 병렬연산을 수행하기 위해 병렬 구조로 설계되었다는 점이 가장 큰 변화입니다.</p>

<p>총 8개의 레이어로 이루어져 있으며, 5개는 Conv 레이어, 3개는 FC 레이어로 구성되어 있습니다. (맨 왼쪽은 input data입니다.)</p>

<p>2, 4, 5번째 컨볼루션 레이어들은 전 단계의 feature map과 연결되어 있지만, 3번째 레이어에서는 병렬처리로 나뉜 두 단계의 feature맵과 모두 연결되어 있는 것이 특징입니다.</p>

<p>더 자세한 내용은 다음 링크에 설명이 되어있습니다.</p>

<ul>
  <li>링크</li>
</ul>

<hr />

<p>용어 검색</p>

<ul>
  <li>overlapping max pooling</li>
  <li>local response normalization</li>
</ul>

<hr />

<h6 id="출처">출처</h6>

<ul>
  <li>
    <p>AIFFEL LMS</p>

    <p>문제시 연락 부탁드립니다. :)</p>
  </li>
</ul>

<h6 id="참고사이트">참고사이트</h6>

<ul>
  <li>https://bskyvision.com/421</li>
</ul>
