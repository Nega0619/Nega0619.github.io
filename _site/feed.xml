<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-02-12T22:14:08+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Hwi’s footsteps</title><subtitle>Artificial Intelligence trends and concepts made easy.</subtitle><author><name>Armando Maynez</name></author><entry><title type="html">[fd_22] 딥네트워크, 서로 뭐가 다른 거죠</title><link href="http://localhost:4000/fd_22-%EB%94%A5%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC,-%EC%84%9C%EB%A1%9C-%EB%AD%90%EA%B0%80-%EB%8B%A4%EB%A5%B8-%EA%B1%B0%EC%A3%A0.html" rel="alternate" type="text/html" title="[fd_22] 딥네트워크, 서로 뭐가 다른 거죠" /><published>2022-02-04T00:00:00+09:00</published><updated>2022-02-04T00:00:00+09:00</updated><id>http://localhost:4000/%5Bfd_22%5D%20%EB%94%A5%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC,%20%EC%84%9C%EB%A1%9C%20%EB%AD%90%EA%B0%80%20%EB%8B%A4%EB%A5%B8%20%EA%B1%B0%EC%A3%A0</id><content type="html" xml:base="http://localhost:4000/fd_22-%EB%94%A5%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC,-%EC%84%9C%EB%A1%9C-%EB%AD%90%EA%B0%80-%EB%8B%A4%EB%A5%B8-%EA%B1%B0%EC%A3%A0.html"><![CDATA[<p>해당 포스팅은, 아이펠 Fundamental 22번 노드를 학습하고 작성한 기록물 입니다.</p>

<p>&lt; 목차 &gt;</p>

<ol>
  <li>
    <p>pre-trainded 모델이란?</p>
  </li>
  <li>
    <p>AlexNet</p>
  </li>
  <li>
    <p>vGG-16</p>
  </li>
</ol>

<ul>
  <li></li>
</ul>

<h1 id="1-pre-trained-모델이란">1. pre-trained 모델이란?</h1>

<p>이미 배워왔듯, 신경망을 깊이 쌓는다고 해서 무조건 성능이 좋아지는 것은 아닙니다. 신경망을 깊게 쌓을 수록 overfitting문제와 학습될 parameter들이 기하급수적으로 증가하는 문제, 이와 더불어 연산속도와 학습속도에 오래걸리는 등 다양한 문제가 발생합니다.</p>

<p>그렇기 때문에, 연구자들이 더 좋은 성능을 내는 딥러닝 신경망을 만들기 위해 다양한 방법을 시도하였고, 많은 네트워크들이 탄생했습니다. 다음은 그 중 몇가지 예시인 pre-trained 모델 리스트입니다.</p>

<p><img src="../images/pages/F-22-2.max-800x600_hpMcSFb.png" alt="content img" /></p>

<p>[Pre-trained 모델의 구조]</p>

<ul>
  <li>여기서 더 볼수있습니다 : https://github.com/tensorflow/models/tree/master/research/slim</li>
</ul>

<h1 id="2-alexnet">2. AlexNet</h1>

<p>2012년 Image Classification Task에서 Geoffrey Hinton 교수님이 이끄는 토론토 대학의 SuperVision팀이 오류율 16%로 1등을 달성합니다. 작년의 우승자는 오류율 26%, 제작년은 28%였으니 엄청난 차이를 보여준것입니다. superVision팀이 사용한 모델이 AlexNet입니다.</p>

<p><img src="../images/pages/99FEB93C5C80B5192E" alt="img" /></p>

<h2 id="alexnet-구조">AlexNet 구조</h2>

<p>기본 구조는 <a href="https://bskyvision.com/418">LeNet-5</a>와 크게 다르지 않습니다. 2개의  GPU로 병렬연산을 수행하기 위해 병렬 구조로 설계되었다는 점이 가장 큰 변화입니다.</p>

<p>총 8개의 레이어로 이루어져 있으며, 5개는 Conv 레이어, 3개는 FC 레이어로 구성되어 있습니다. (맨 왼쪽은 input data입니다.)</p>

<p>2, 4, 5번째 컨볼루션 레이어들은 전 단계의 feature map과 연결되어 있지만, 3번째 레이어에서는 병렬처리로 나뉜 두 단계의 feature맵과 모두 연결되어 있는 것이 특징입니다.</p>

<p>더 자세한 내용은 다음 링크에 설명이 되어있습니다.</p>

<ul>
  <li>링크</li>
</ul>

<hr />

<p>용어 검색</p>

<ul>
  <li>overlapping max pooling</li>
  <li>local response normalization</li>
</ul>

<hr />

<h6 id="출처">출처</h6>

<ul>
  <li>
    <p>AIFFEL LMS</p>

    <p>문제시 연락 부탁드립니다. :)</p>
  </li>
</ul>

<h6 id="참고사이트">참고사이트</h6>

<ul>
  <li>https://bskyvision.com/421</li>
</ul>]]></content><author><name>Armando Maynez</name></author><summary type="html"><![CDATA[해당 포스팅은, 아이펠 Fundamental 22번 노드를 학습하고 작성한 기록물 입니다.]]></summary></entry><entry><title type="html">[유용한 파이썬 함수사이트]</title><link href="http://localhost:4000/%EC%9C%A0%EC%9A%A9%ED%95%9C-%ED%8C%8C%EC%9D%B4%EC%8D%AC-%ED%95%A8%EC%88%98%EC%82%AC%EC%9D%B4%ED%8A%B8.txt" rel="alternate" type="text/html" title="[유용한 파이썬 함수사이트]" /><published>2022-02-04T00:00:00+09:00</published><updated>2022-02-04T00:00:00+09:00</updated><id>http://localhost:4000/%5B%EC%9C%A0%EC%9A%A9%ED%95%9C%20%ED%8C%8C%EC%9D%B4%EC%8D%AC%20%ED%95%A8%EC%88%98%EC%82%AC%EC%9D%B4%ED%8A%B8%5D</id><content type="html" xml:base="http://localhost:4000/%EC%9C%A0%EC%9A%A9%ED%95%9C-%ED%8C%8C%EC%9D%B4%EC%8D%AC-%ED%95%A8%EC%88%98%EC%82%AC%EC%9D%B4%ED%8A%B8.txt"><![CDATA[- timestamp to datetime
https://ddolcat.tistory.com/660]]></content><author><name>Armando Maynez</name></author><summary type="html"><![CDATA[- timestamp to datetime https://ddolcat.tistory.com/660]]></summary></entry><entry><title type="html">강화학습이란</title><link href="http://localhost:4000/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5%EC%9D%B4%EB%9E%80.html" rel="alternate" type="text/html" title="강화학습이란" /><published>2022-02-03T00:00:00+09:00</published><updated>2022-02-03T00:00:00+09:00</updated><id>http://localhost:4000/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5%EC%9D%B4%EB%9E%80</id><content type="html" xml:base="http://localhost:4000/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5%EC%9D%B4%EB%9E%80.html"><![CDATA[<p>요즘 한창 열심히 하는 것 중 하나가  <code class="language-plaintext highlighter-rouge">강화학습 스터디-N강 성공</code>참여입니다. 무려 스터디장님이 열심히 해주셔서 감사하다는 말씀도 해주셔서 기분이 좋은 오늘, 영어강의의 이해 한계를 극복하고자 한국어 책을 보고 강화학습 이론을 정리해 보았습니다.</p>

<p>참고한 책은 다음과 같습니다.</p>

<p><code class="language-plaintext highlighter-rouge">밑바닥부터 시작하는 딥러닝 1</code></p>

<p><code class="language-plaintext highlighter-rouge">딥러닝의 정석 : 텐서플로우와 최신 기법으로 배우는 딥러닝 알고리즘 설계'</code></p>

<p>시작합니다.</p>

<h1 id="강화학습-개요">강화학습 개요</h1>

<p>강화학습의 주체에는 크게 에이전트와 환경이 있습니다.</p>

<p>에이전트가 환경에 맞게 행동을 선택하면, 행동에 맞게 환경이 변하는 것이 기본적인 틀입니다. 환경이 변화하면 에이전트는 보상을 얻게 되는데, 강화학습의 목적은 더 나은 보상을 받도록 에이전트의 행동 강령을 세우는 것입니다.</p>

<p>여기서 주의할 점은 보상은 정해진 것이 아니라 <code class="language-plaintext highlighter-rouge">예상보상</code>입니다. 보상은 어떤 환경이었는지에 따라 천차만별이기 때문입니다. 예를 들어 요리를 하다 <code class="language-plaintext highlighter-rouge">불을 끈다.</code>라는 행동의 보상은 요리를 다해서 불을 끈다, 후라이팬에 불이 붙어서 불을 끈다. 두 상황에 따라 보상이 천차만별일 것입니다. 그렇기 때문에, 이러한 불명확한 상황에서는 안전의 위험 혹은 요리의 완성과 같은 명확한 지표로부터 역산하여 <code class="language-plaintext highlighter-rouge">예상 보상</code>을 정해야 합니다.</p>]]></content><author><name>Armando Maynez</name></author><summary type="html"><![CDATA[요즘 한창 열심히 하는 것 중 하나가 강화학습 스터디-N강 성공참여입니다. 무려 스터디장님이 열심히 해주셔서 감사하다는 말씀도 해주셔서 기분이 좋은 오늘, 영어강의의 이해 한계를 극복하고자 한국어 책을 보고 강화학습 이론을 정리해 보았습니다.]]></summary></entry><entry><title type="html">[ex_09] 폐렴아 기다려라</title><link href="http://localhost:4000/ex_09-%ED%8F%90%EB%A0%B4%EC%95%84-%EA%B8%B0%EB%8B%A4%EB%A0%A4%EB%9D%BC.html" rel="alternate" type="text/html" title="[ex_09] 폐렴아 기다려라" /><published>2022-02-03T00:00:00+09:00</published><updated>2022-02-03T00:00:00+09:00</updated><id>http://localhost:4000/%5Bex_09%5D%20%ED%8F%90%EB%A0%B4%EC%95%84%20%EA%B8%B0%EB%8B%A4%EB%A0%A4%EB%9D%BC</id><content type="html" xml:base="http://localhost:4000/ex_09-%ED%8F%90%EB%A0%B4%EC%95%84-%EA%B8%B0%EB%8B%A4%EB%A0%A4%EB%9D%BC.html"><![CDATA[<p>해당 포스팅은, 아이펠 Exploration 9번 노드를 학습하고 작성한 기록물 입니다.</p>

<p>의료영상에 딥러닝을 접목시켜 분석하는 실습을 해보았으며, 사용한 데이터는 캐글의 폐렴환자 데이터입니다.</p>

<p>Chest X-Ray Images (Pneumonia)</p>

<p>https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia</p>

<h1 id="목차">목차</h1>

<ul>
  <li>의료 영상에 대한 기초 지식 쌓기</li>
  <li>의료 영상 데이터 처리하기</li>
</ul>

<h1 id="1-의료영상에-대한-기초-지식-쌓기">1. 의료영상에 대한 기초 지식 쌓기</h1>

<h2 id="1-1-의료-영상-분석과-일반적인-이미지-처리가-다른-점">1-1. 의료 영상 분석과 일반적인 이미지 처리가 다른 점</h2>

<ul>
  <li>
    <p>의료 이미지는 개인정보문제가 있어 데이터를 구하는 것 자체가 쉽지 않음</p>
  </li>
  <li>
    <p>라벨링 작업 자체가 의학적 전문 지식을 요하므로 데이터 셋 구축 비용이 비쌈</p>

    <ul>
      <li>장기 판별 /수술 기구 판별</li>
    </ul>
  </li>
  <li>
    <p>희귀질병의 경우, 데이터 입수 자체가 어려움</p>
  </li>
  <li>
    <p>음성/양성 데이터간 imbalance가 심함 -&gt; 학습에 주의 필요</p>
  </li>
  <li>
    <p>이미지만으로 진단은 어려움 -&gt; 다른 데이터와 결합하여 학습해야 하는 경우 有</p>

    <p>즉, 딥러닝 영상처리 기술 + 의학적 도메인 지식 + 의료 영상에 대한 명확한 이해 필요</p>
  </li>
</ul>

<h2 id="1-2-의료-영상-종류">1-2. 의료 영상 종류</h2>

<h3 id="x-ray">X-ray</h3>

<p>전자를 물체에 충돌시킬 때 발생하는 투과력이 강한 복사선(전자기파)</p>

<p>방사선의 일종</p>

<p>방, 근육, 천, 종이같이 밀도가 낮은 것은 수월하게 통과하지만, 밀도가 높은 뼈, 금속 같은 물질은 잘 통과하지 못합니다.</p>

<p><img src="https://raw.githubusercontent.com/Nega0619/typora_img/main/img/image-20220203110505646.png?token=ATH7GGPOOTKL2N73WSV2S6LB7M4JI" alt="image-20220203110505646" /></p>

<p>사진 출처 : http://health.cdc.go.kr/healthinfo/index.jsp</p>

<h3 id="ct">CT</h3>

<p>Computed Tomography</p>

<p>환자를 중심으로 X-RAY를 빠르게 회전하여 3D 이미지를 만들어내는 영상</p>

<p>3 차원 이미지를 형성하여 기본 구조와 종양 또는 이상을 쉽게 식별하고 위치를 파악가능</p>

<p>신체의 단면 이미지는 slice라고 함</p>

<p>Slice는 단층 촬영 이미지라고도 함</p>

<p>기존의 X-RAY보다 더 자세한 정보를 포함</p>

<p><img src="https://raw.githubusercontent.com/Nega0619/typora_img/main/img/image-20220203110806670.png?token=ATH7GGNHSOMDJTB4VVS25ULB7M4UO" alt="image-20220203110806670" /></p>

<p>http://www.nibib.nih.gov/science-education/science-topics/computed-tomography-ct</p>

<p><img src="https://raw.githubusercontent.com/Nega0619/typora_img/main/img/image-20220203110812824.png?token=ATH7GGIED4BHBT23CP6NONLB7M4UW" alt="image-20220203110812824" /></p>

<p>http://en.wikipedia.org/wiki/CT_scan</p>

<h3 id="mri">MRI</h3>

<p>Magnetic Resonance Imaging(자기 공명 영상)</p>

<p>신체의 해부학적 과정과 생리적 과정을 보기 위해 사용</p>

<p>강한 자기장를 사용 -&gt; 신체 기관의 이미지 생성</p>

<p>방사선을 사용X -&gt; CT나 X-ray보다는 안전</p>

<p><img src="https://raw.githubusercontent.com/Nega0619/typora_img/main/img/image-20220203110927967.png?token=ATH7GGIIZBZGLSC2C3WF32TB7M4ZM" alt="image-20220203110927967" /></p>

<p><a href="http://en.wikipedia.org/wiki/Magnetic_resonance_imaging#:~:text=Magnetic resonance imaging (MRI) is,the organs in the body">http://en.wikipedia.org/wiki/Magnetic_resonance_imaging#:~:text=Magnetic%20resonance%20imaging%20(MRI)%20is,the%20organs%20in%20the%20body</a></p>

<h2 id="1-3-x-ray-이미지">1-3. X-ray 이미지</h2>

<h3 id="x-ray-자세-분류-체계">X-ray 자세 분류 체계</h3>

<p><img src="https://raw.githubusercontent.com/Nega0619/typora_img/main/img/image-20220203112206104.png?token=ATH7GGM4IW7YGGGTIP3KKULB7M6I2" alt="image-20220203112206104" /></p>

<p><a href="https://ko.wikipedia.org/wiki/해부학_용어">https://ko.wikipedia.org/wiki/%ED%95%B4%EB%B6%80%ED%95%99_%EC%9A%A9%EC%96%B4</a></p>

<ul>
  <li>Sagittal plane : 시상면. 사람을 왼쪽과 오른쪽을 나누는 면.</li>
  <li>Coronal plane : 관상면. 인체를 앞뒤로 나누는 면.</li>
  <li>Transverse plane : 횡단면(수평면). 인체를 상하로 나누는 면.</li>
</ul>

<h3 id="해부학적-위치">해부학적 위치</h3>

<p><img src="https://raw.githubusercontent.com/Nega0619/typora_img/main/img/image-20220203112254918.png?token=ATH7GGLNIJOXXCHKWYYHIGTB7M6L6" alt="image-20220203112254918" /></p>

<p><a href="https://ko.wikipedia.org/wiki/해부학_용어">https://ko.wikipedia.org/wiki/%ED%95%B4%EB%B6%80%ED%95%99_%EC%9A%A9%EC%96%B4</a></p>

<p>영상을 볼 때는 보통 정면을 보고 있는 것으로 가정을 하며 위의 이미지에서 오른쪽에 해당합니다.</p>

<p>또한 영상을 볼 때는, 환자중심으로 보기 때문에 오른쪽 얼굴 이라고하면 제가 환자를 마주보는 상황에서 왼쪽 얼굴을 보아야 합니다.</p>

<h3 id="흉부-x-ray">흉부 X-ray</h3>

<p><img src="https://raw.githubusercontent.com/Nega0619/typora_img/main/img/image-20220203113842290.png?token=ATH7GGIZAIVR344BREWJBRDB7NAHE" alt="image-20220203113842290" /></p>

<p>http://health.cdc.go.kr/health/Resource/Module/Content/Printok.do?idx=2110&amp;subIdx=4</p>

<ul>
  <li>갈비뼈 : 하얀색</li>
  <li>폐 : 검은색</li>
  <li>어깨 쪽의 지방 및 근육 : 연한 회색</li>
</ul>

<h2 id="1-4-폐렴-진단해보기">1-4. 폐렴 진단해보기</h2>

<ul>
  <li>사용한 데이터 셋</li>
</ul>

<p>Chest X-Ray Images (Pneumonia)</p>

<p>https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia</p>

<p>(에디터 주) 캐글에서 다운로드한 데이터는 chest_xray 하위에 chest_xray 폴더가 중복으로 포함되어 있어서 전체 데이터의 크기가 2.5GB인 경우가 있습니다. 중복된 데이터는 필요하지 않습니다.</p>

<p>해당 이미지는 중국 광저우에 있는 광저우 여성 및 어린이 병원의 1~5 세 소아 환자의 흉부 X선 영상입니다.</p>

<h3 id="폐렴이란">폐렴이란?</h3>

<blockquote>
  <p>폐렴(pneumonia 뉴모니아)은 폐에 염증이 생긴 상태로 중증의 호흡기 감염병이다. 세균을 통한 감염이 가장 많으며, 바이러스, 균류, 또는 기타 미생물도 원인이 될 수가 있다. 드물게는 알레르기 반응이나 자극적인 화학 물질을 흡입해 발생하기도 한다. 노인이나 어린아이, 혹은 전체적으로 상태가 안 좋은 환자들이나 기침 반사가 약한 사람들에게는 흡인성 폐렴이 발생한다. 그리고 세균이 원인인 경우는 항생제로 치료를 할 수 있다. 항생제가 생기기 전에는 50~90%가 사망할 정도로 위험한 질환이었으나, 현재는 거의 사망하지 않는다. 1940년대에 항생제가 개발되기 전까지는 폐렴 환자의 1/3 정도가 사망하였다. 오늘날에는 적절한 의학적 치료로 폐렴 환자의 95% 이상이 회복된다. 그러나 일부 저개발국(개발 도상국)에서는 폐렴이 여전히 주요 사망 원인 중 하나이다.</p>
</blockquote>

<p>출처 : https://ko.wikipedia.org/wiki/폐렴</p>

<blockquote>
  <p>염증은 유해한 자극에 대한 생체반응 중 하나로 면역세포, 혈관, 염증 매개체들이 관여하는 보호반응이다. 염증의 목적은 세포의 손상을 초기 단계에서 억제하고, 상처 부분의 파괴된 조직 및 괴사된 세포를 제거하며, 동시에 조직을 재생하는 것이다.</p>
</blockquote>

<p>출처 : https://ko.wikipedia.org/wiki/염증</p>

<p>정리하자면, 폐렴은 폐에 염증이 생기는 것이며, 염증은 백혈구들이 세균 등에 맞서 싸우고 있는 장소입니다.</p>

<h3 id="폐렴-구별법">폐렴 구별법</h3>

<p><img src="https://raw.githubusercontent.com/Nega0619/typora_img/main/img/image-20220203115450159.png?token=ATH7GGPQ5QNGLRTTCOWMYCTB7NCDS" alt="image-20220203115450159" /></p>

<p>폐렴의 경우, X-ray 사진에서 다양한 양상의 음영이 보입니다. 깨끗해야 할 폐 부위에 희미한 그림자가 관찰되는 것입니다. 하지만, 실제 영상을 보면, 희미한 케이스가 많으므로 그 희미함이 폐렴에 의한 것인지, 다른 이유인지는 파악하기 어렵습니다.</p>

<p><img src="https://raw.githubusercontent.com/Nega0619/typora_img/main/img/image-20220203115504878.png?token=ATH7GGLUUYXWQH56TO6YX6LB7NCEQ" alt="image-20220203115504878" /></p>

<p>왼쪽은 정상, 중간은 세균성 폐렴, 오른쪽은 바이러스 폐렴입니다.</p>

<p>세균성 폐렴은 일반적으로 왼쪽 상부 엽(하얀 화살표)에 하얀 부분이 관찰되며, 바이러스성 폐렴은 확산된 “interstitial(조직 사이에 있는)” 패턴으로 나타납니다.</p>

<h1 id="2-의료-영상-데이터-처리하기">2. 의료 영상 데이터 처리하기</h1>

<p>실습 코드는 아래 URL에서 확인하실 수 있으며, 포스팅에는 제가 정확도를 향상시키기 위하여 사용한 아이디어 혹은 새로 배운점 위주로 작성하였습니다.</p>

<h3 id="2-1-inbalance한-데이터를-학습할-때-주의점">2-1. inbalance한 데이터를 학습할 때 주의점</h3>

<h3 id="inbalance한-데이터란">inbalance한 데이터란?</h3>

<p>해당 코드글에서 보실 수 있겠지만, 캐글 폐렴 환자 데이터에서</p>

<h4 id="train-data">train data</h4>

<p>CNN 모델의 경우, 데이터가 클래스 별 balance가 좋을 수록 train을 잘 합니다. 그렇기 때문에  imbalance 문제를 꼭 해결해 주어야합니다.</p>

<h4 id="test-data">test data</h4>

<p>test 데이터는 평가 하기 위해서 사용하기 때문에 학습과 관련이 없어서 inbalance한 데이터 셋이어도 상관없습니다.</p>

<h4 id="validation-data">validation data</h4>

<p>validation 데이터는 평가 하기 위해서 사용하기 때문에 학습과 관련이 없어서 inbalance한 데이터 셋이어도 상관없습니다.</p>

<h3 id="inbalance한-데이터-처리-방법">inbalance한 데이터 처리 방법</h3>

<h4 id="weight-balancing-테크닉-사용">Weight balancing 테크닉 사용</h4>

<p>Weight balancing 은 training set의 각 데이터에서 loss를 계산할 때 특정 클래스의 데이터에 더 큰 loss 값을 갖도록 가중치를 부여하는 방법입니다. Keras는 model.fit()을 호출할 때 파라미터로 넘기는 class_weight 에 이러한 클래스별 가중치를 세팅할 수 있도록 지원하고 있습니다.</p>

<hr />

<p>참고 링크</p>

<p>딥러닝에서 클래스 불균형을 다루는 방법 : https://3months.tistory.com/414</p>

<hr />

<h2 id="2-2-새로-배운-코드">2-2. 새로 배운 코드</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_filenames</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">gfile</span><span class="p">.</span><span class="n">glob</span><span class="p">(</span><span class="n">TRAIN_PATH</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Normal image path</span><span class="se">\n</span><span class="si">{</span><span class="n">filenames</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Pneumonia image path</span><span class="se">\n</span><span class="si">{</span><span class="n">filenames</span><span class="p">[</span><span class="mi">2000</span><span class="p">]</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_list_ds</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">train_filenames</span><span class="p">)</span>
<span class="n">val_list_ds</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">val_filenames</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Train 데이터셋, validation 데이터셋 개수 확인을 해보겠습니다.
</span>
<span class="n">TRAIN_IMG_COUNT</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">cardinality</span><span class="p">(</span><span class="n">train_list_ds</span><span class="p">).</span><span class="n">numpy</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Training images count: </span><span class="si">{</span><span class="n">TRAIN_IMG_COUNT</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="n">VAL_IMG_COUNT</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">cardinality</span><span class="p">(</span><span class="n">val_list_ds</span><span class="p">).</span><span class="n">numpy</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Validating images count: </span><span class="si">{</span><span class="n">VAL_IMG_COUNT</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_ds</span> <span class="o">=</span> <span class="n">train_list_ds</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="n">process_path</span><span class="p">,</span> <span class="n">num_parallel_calls</span><span class="o">=</span><span class="n">AUTOTUNE</span><span class="p">)</span>
<span class="n">val_ds</span> <span class="o">=</span> <span class="n">val_list_ds</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="n">process_path</span><span class="p">,</span> <span class="n">num_parallel_calls</span><span class="o">=</span><span class="n">AUTOTUNE</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">prepare_for_training</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="n">shuffle_buffer_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">shuffle_buffer_size</span><span class="p">)</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="p">.</span><span class="n">repeat</span><span class="p">()</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="p">.</span><span class="n">batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="p">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">AUTOTUNE</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ds</span>

<span class="n">train_ds</span> <span class="o">=</span> <span class="n">prepare_for_training</span><span class="p">(</span><span class="n">train_ds</span><span class="p">)</span>
<span class="n">val_ds</span> <span class="o">=</span> <span class="n">prepare_for_training</span><span class="p">(</span><span class="n">val_ds</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">conv_block</span><span class="p">(</span><span class="n">filters</span><span class="p">):</span>
    <span class="n">block</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">([</span>
        <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">SeparableConv2D</span><span class="p">(</span><span class="n">filters</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">),</span>
        <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">SeparableConv2D</span><span class="p">(</span><span class="n">filters</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">),</span>
        <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
        <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPool2D</span><span class="p">()</span>
    <span class="p">])</span>
    
    <span class="k">return</span> <span class="n">block</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">augment</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">label</span><span class="p">):</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="n">random_flip_left_right</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>  <span class="c1"># 랜덤하게 좌우를 반전합니다.
</span>    <span class="k">return</span> <span class="n">image</span><span class="p">,</span><span class="n">label</span>

<span class="k">def</span> <span class="nf">prepare_for_training</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="n">shuffle_buffer_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="c1"># augment 적용 부분이 배치처리 함수에 추가되었습니다.
</span>    <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span>
            <span class="n">augment</span><span class="p">,</span>       <span class="c1"># augment 함수 적용
</span>            <span class="n">num_parallel_calls</span><span class="o">=</span><span class="mi">2</span>
        <span class="p">)</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">shuffle_buffer_size</span><span class="p">)</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="p">.</span><span class="n">repeat</span><span class="p">()</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="p">.</span><span class="n">batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="p">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">AUTOTUNE</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">ds</span>
</code></pre></div></div>

<p>저 9-7에서 augment 함수 궁금한게.. 저 함수만 입력해도 훈련데이터가 늘어나는 건가요? 아니면 따로 데이터 합치는 코드를 써야하나요?</p>

<p>이래저래 시도했을 때 제가 지금까지 내린 결론은 1) 데이터 양은 계속 동일한데, 2) random하게 flip해주는 걸 추가하고, 3) 덧붙여 repeat()이란 걸 붙여놓으면, 4) 데이터 개수가 무한개로 많아지는데 그 중에 flipped된 종류가 생긴다 인 것 같아요</p>

<p>음… ㅋㅋ 일단 좌우로 flip하는 게 성능 향상에 도움을 준다는 의견이 있긴 해서 한번 따라보겠습니다…ㅋㅋ https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/discussion/66130</p>

<h2 id="2-3-batch-normalization과-dropout을-같이-써도-되는가-안되는가">2-3. Batch Normalization과 Dropout을 같이 써도 되는가? 안되는가?</h2>

<hr />

<p>참고 논문 1.</p>

<p>Understanding the Disharmony between Dropout and Batch Normalization by Variance Shift</p>

<ul>
  <li>chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/viewer.html?pdfurl=https%3A%2F%2Fopenaccess.thecvf.com%2Fcontent_CVPR_2019%2Fpapers%2FLi_Understanding_the_Disharmony_Between_Dropout_and_Batch_Normalization_by_Variance_CVPR_2019_paper.pdf&amp;clen=1272425&amp;chunk=true</li>
</ul>

<p>참고 논문 2.</p>

<p>Rethinking the Usage of Batch Normalization and Dropout in the Training of Deep</p>

<ul>
  <li>chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/viewer.html?pdfurl=https%3A%2F%2Farxiv.org%2Fpdf%2F1905.05928.pdf&amp;clen=856720&amp;chunk=true</li>
</ul>

<hr />

<hr />

<h6 id="출처">출처</h6>

<ul>
  <li>
    <p>AIFFEL LMS</p>

    <p>문제시 연락 부탁드립니다. :)</p>
  </li>
</ul>]]></content><author><name>Armando Maynez</name></author><summary type="html"><![CDATA[해당 포스팅은, 아이펠 Exploration 9번 노드를 학습하고 작성한 기록물 입니다.]]></summary></entry><entry><title type="html">[ex_09] 폐렴아 기다려라 성능개선</title><link href="http://localhost:4000/ex_09-%ED%8F%90%EB%A0%B4%EC%95%84-%EA%B8%B0%EB%8B%A4%EB%A0%A4%EB%9D%BC-%EC%84%B1%EB%8A%A5%EA%B0%9C%EC%84%A0.html" rel="alternate" type="text/html" title="[ex_09] 폐렴아 기다려라 성능개선" /><published>2022-02-03T00:00:00+09:00</published><updated>2022-02-03T00:00:00+09:00</updated><id>http://localhost:4000/%5Bex_09%5D%20%ED%8F%90%EB%A0%B4%EC%95%84%20%EA%B8%B0%EB%8B%A4%EB%A0%A4%EB%9D%BC%20-%20%EC%84%B1%EB%8A%A5%EA%B0%9C%EC%84%A0</id><content type="html" xml:base="http://localhost:4000/ex_09-%ED%8F%90%EB%A0%B4%EC%95%84-%EA%B8%B0%EB%8B%A4%EB%A0%A4%EB%9D%BC-%EC%84%B1%EB%8A%A5%EA%B0%9C%EC%84%A0.html"><![CDATA[<p>해당 포스팅은, 아이펠 Exploration 9번 노드를 학습하고 작성한 기록물 입니다.</p>

<p>의료영상에 딥러닝을 접목시켜 분석하는 실습을 해보았으며, 사용한 데이터는 캐글의 폐렴환자 데이터입니다.</p>

<p>Chest X-Ray Images (Pneumonia)</p>

<p>https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia</p>

<h1 id="목차">목차</h1>

<ul>
  <li>기존의 성능</li>
  <li>성능 개선 계획</li>
  <li>성능 개선 결과</li>
</ul>

<h1 id="기존의-성능">기존의 성능</h1>

<h2 id="전처리">전처리</h2>

<h2 id="모델-아키텍처">모델 아키텍처</h2>

<h1 id="성능-개선-계획">성능 개선 계획</h1>

<h2 id="전처리-1">전처리</h2>

<h2 id="모델-아키텍처-1">모델 아키텍처</h2>

<hr />

<h6 id="출처">출처</h6>

<ul>
  <li>
    <p>AIFFEL LMS</p>

    <p>문제시 연락 부탁드립니다. :)</p>
  </li>
</ul>]]></content><author><name>Armando Maynez</name></author><summary type="html"><![CDATA[해당 포스팅은, 아이펠 Exploration 9번 노드를 학습하고 작성한 기록물 입니다.]]></summary></entry><entry><title type="html">[ex_08] 뉴스 요약봇 만들기</title><link href="http://localhost:4000/ex_08-%EB%89%B4%EC%8A%A4-%EC%9A%94%EC%95%BD%EB%B4%87-%EB%A7%8C%EB%93%A4%EA%B8%B0.html" rel="alternate" type="text/html" title="[ex_08] 뉴스 요약봇 만들기" /><published>2022-02-03T00:00:00+09:00</published><updated>2022-02-03T00:00:00+09:00</updated><id>http://localhost:4000/%5Bex_08%5D%20%EB%89%B4%EC%8A%A4%20%EC%9A%94%EC%95%BD%EB%B4%87%20%EB%A7%8C%EB%93%A4%EA%B8%B0</id><content type="html" xml:base="http://localhost:4000/ex_08-%EB%89%B4%EC%8A%A4-%EC%9A%94%EC%95%BD%EB%B4%87-%EB%A7%8C%EB%93%A4%EA%B8%B0.html"><![CDATA[<p>해당 포스팅은, 아이펠 Exploration 9번 노드를 학습하고 작성한 기록물 입니다.</p>

<p>의료영상에 딥러닝을 접목시켜 분석하는 실습을 해보았으며, 사용한 데이터는 캐글의 폐렴환자 데이터입니다.</p>

<p>Chest X-Ray Images (Pneumonia)</p>

<p>https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia</p>

<h1 id="목차">목차</h1>

<ul>
  <li>의료 영상에 대한 기초 지식 쌓기</li>
  <li>의료 영상 데이터 처리하기</li>
</ul>

<h1 id="1-의료영상에-대한-기초-지식-쌓기">1. 의료영상에 대한 기초 지식 쌓기</h1>

<h2 id="1-1-의료-영상-분석과-일반적인-이미지-처리가-다른-점">1-1. 의료 영상 분석과 일반적인 이미지 처리가 다른 점</h2>

<ul>
  <li>
    <p>의료 이미지는 개인정보문제가 있어 데이터를 구하는 것 자체가 쉽지 않음</p>
  </li>
  <li>
    <p>라벨링 작업 자체가 의학적 전문 지식을 요하므로 데이터 셋 구축 비용이 비쌈</p>

    <ul>
      <li>장기 판별 /수술 기구 판별</li>
    </ul>
  </li>
  <li>
    <p>희귀질병의 경우, 데이터 입수 자체가 어려움</p>
  </li>
  <li>
    <p>음성/양성 데이터간 imbalance가 심함 -&gt; 학습에 주의 필요</p>
  </li>
  <li>
    <p>이미지만으로 진단은 어려움 -&gt; 다른 데이터와 결합하여 학습해야 하는 경우 有</p>

    <p>즉, 딥러닝 영상처리 기술 + 의학적 도메인 지식 + 의료 영상에 대한 명확한 이해 필요</p>
  </li>
</ul>

<h2 id="1-2-의료-영상-종류">1-2. 의료 영상 종류</h2>

<h3 id="x-ray">X-ray</h3>

<p>전자를 물체에 충돌시킬 때 발생하는 투과력이 강한 복사선(전자기파)</p>

<p>방사선의 일종</p>

<p>방, 근육, 천, 종이같이 밀도가 낮은 것은 수월하게 통과하지만, 밀도가 높은 뼈, 금속 같은 물질은 잘 통과하지 못합니다.</p>

<p><img src="https://raw.githubusercontent.com/Nega0619/typora_img/main/img/image-20220203110505646.png?token=ATH7GGPOOTKL2N73WSV2S6LB7M4JI" alt="image-20220203110505646" /></p>

<p>사진 출처 : http://health.cdc.go.kr/healthinfo/index.jsp</p>

<h3 id="ct">CT</h3>

<p>Computed Tomography</p>

<p>환자를 중심으로 X-RAY를 빠르게 회전하여 3D 이미지를 만들어내는 영상</p>

<p>3 차원 이미지를 형성하여 기본 구조와 종양 또는 이상을 쉽게 식별하고 위치를 파악가능</p>

<p>신체의 단면 이미지는 slice라고 함</p>

<p>Slice는 단층 촬영 이미지라고도 함</p>

<p>기존의 X-RAY보다 더 자세한 정보를 포함</p>

<p><img src="https://raw.githubusercontent.com/Nega0619/typora_img/main/img/image-20220203110806670.png?token=ATH7GGNHSOMDJTB4VVS25ULB7M4UO" alt="image-20220203110806670" /></p>

<p>http://www.nibib.nih.gov/science-education/science-topics/computed-tomography-ct</p>

<p><img src="https://raw.githubusercontent.com/Nega0619/typora_img/main/img/image-20220203110812824.png?token=ATH7GGIED4BHBT23CP6NONLB7M4UW" alt="image-20220203110812824" /></p>

<p>http://en.wikipedia.org/wiki/CT_scan</p>

<h3 id="mri">MRI</h3>

<p>Magnetic Resonance Imaging(자기 공명 영상)</p>

<p>신체의 해부학적 과정과 생리적 과정을 보기 위해 사용</p>

<p>강한 자기장를 사용 -&gt; 신체 기관의 이미지 생성</p>

<p>방사선을 사용X -&gt; CT나 X-ray보다는 안전</p>

<p><img src="https://raw.githubusercontent.com/Nega0619/typora_img/main/img/image-20220203110927967.png?token=ATH7GGIIZBZGLSC2C3WF32TB7M4ZM" alt="image-20220203110927967" /></p>

<p><a href="http://en.wikipedia.org/wiki/Magnetic_resonance_imaging#:~:text=Magnetic resonance imaging (MRI) is,the organs in the body">http://en.wikipedia.org/wiki/Magnetic_resonance_imaging#:~:text=Magnetic%20resonance%20imaging%20(MRI)%20is,the%20organs%20in%20the%20body</a></p>

<h2 id="1-3-x-ray-이미지">1-3. X-ray 이미지</h2>

<h3 id="x-ray-자세-분류-체계">X-ray 자세 분류 체계</h3>

<p><img src="https://raw.githubusercontent.com/Nega0619/typora_img/main/img/image-20220203112206104.png?token=ATH7GGM4IW7YGGGTIP3KKULB7M6I2" alt="image-20220203112206104" /></p>

<p><a href="https://ko.wikipedia.org/wiki/해부학_용어">https://ko.wikipedia.org/wiki/%ED%95%B4%EB%B6%80%ED%95%99_%EC%9A%A9%EC%96%B4</a></p>

<ul>
  <li>Sagittal plane : 시상면. 사람을 왼쪽과 오른쪽을 나누는 면.</li>
  <li>Coronal plane : 관상면. 인체를 앞뒤로 나누는 면.</li>
  <li>Transverse plane : 횡단면(수평면). 인체를 상하로 나누는 면.</li>
</ul>

<h3 id="해부학적-위치">해부학적 위치</h3>

<p><img src="https://raw.githubusercontent.com/Nega0619/typora_img/main/img/image-20220203112254918.png?token=ATH7GGLNIJOXXCHKWYYHIGTB7M6L6" alt="image-20220203112254918" /></p>

<p><a href="https://ko.wikipedia.org/wiki/해부학_용어">https://ko.wikipedia.org/wiki/%ED%95%B4%EB%B6%80%ED%95%99_%EC%9A%A9%EC%96%B4</a></p>

<p>영상을 볼 때는 보통 정면을 보고 있는 것으로 가정을 하며 위의 이미지에서 오른쪽에 해당합니다.</p>

<p>또한 영상을 볼 때는, 환자중심으로 보기 때문에 오른쪽 얼굴 이라고하면 제가 환자를 마주보는 상황에서 왼쪽 얼굴을 보아야 합니다.</p>

<h3 id="흉부-x-ray">흉부 X-ray</h3>

<p><img src="https://raw.githubusercontent.com/Nega0619/typora_img/main/img/image-20220203113842290.png?token=ATH7GGIZAIVR344BREWJBRDB7NAHE" alt="image-20220203113842290" /></p>

<p>http://health.cdc.go.kr/health/Resource/Module/Content/Printok.do?idx=2110&amp;subIdx=4</p>

<ul>
  <li>갈비뼈 : 하얀색</li>
  <li>폐 : 검은색</li>
  <li>어깨 쪽의 지방 및 근육 : 연한 회색</li>
</ul>

<h2 id="1-4-폐렴-진단해보기">1-4. 폐렴 진단해보기</h2>

<ul>
  <li>사용한 데이터 셋</li>
</ul>

<p>Chest X-Ray Images (Pneumonia)</p>

<p>https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia</p>

<p>(에디터 주) 캐글에서 다운로드한 데이터는 chest_xray 하위에 chest_xray 폴더가 중복으로 포함되어 있어서 전체 데이터의 크기가 2.5GB인 경우가 있습니다. 중복된 데이터는 필요하지 않습니다.</p>

<p>해당 이미지는 중국 광저우에 있는 광저우 여성 및 어린이 병원의 1~5 세 소아 환자의 흉부 X선 영상입니다.</p>

<h3 id="폐렴이란">폐렴이란?</h3>

<blockquote>
  <p>폐렴(pneumonia 뉴모니아)은 폐에 염증이 생긴 상태로 중증의 호흡기 감염병이다. 세균을 통한 감염이 가장 많으며, 바이러스, 균류, 또는 기타 미생물도 원인이 될 수가 있다. 드물게는 알레르기 반응이나 자극적인 화학 물질을 흡입해 발생하기도 한다. 노인이나 어린아이, 혹은 전체적으로 상태가 안 좋은 환자들이나 기침 반사가 약한 사람들에게는 흡인성 폐렴이 발생한다. 그리고 세균이 원인인 경우는 항생제로 치료를 할 수 있다. 항생제가 생기기 전에는 50~90%가 사망할 정도로 위험한 질환이었으나, 현재는 거의 사망하지 않는다. 1940년대에 항생제가 개발되기 전까지는 폐렴 환자의 1/3 정도가 사망하였다. 오늘날에는 적절한 의학적 치료로 폐렴 환자의 95% 이상이 회복된다. 그러나 일부 저개발국(개발 도상국)에서는 폐렴이 여전히 주요 사망 원인 중 하나이다.</p>
</blockquote>

<p>출처 : https://ko.wikipedia.org/wiki/폐렴</p>

<blockquote>
  <p>염증은 유해한 자극에 대한 생체반응 중 하나로 면역세포, 혈관, 염증 매개체들이 관여하는 보호반응이다. 염증의 목적은 세포의 손상을 초기 단계에서 억제하고, 상처 부분의 파괴된 조직 및 괴사된 세포를 제거하며, 동시에 조직을 재생하는 것이다.</p>
</blockquote>

<p>출처 : https://ko.wikipedia.org/wiki/염증</p>

<p>정리하자면, 폐렴은 폐에 염증이 생기는 것이며, 염증은 백혈구들이 세균 등에 맞서 싸우고 있는 장소입니다.</p>

<h3 id="폐렴-구별법">폐렴 구별법</h3>

<p><img src="https://raw.githubusercontent.com/Nega0619/typora_img/main/img/image-20220203115450159.png?token=ATH7GGPQ5QNGLRTTCOWMYCTB7NCDS" alt="image-20220203115450159" /></p>

<p>폐렴의 경우, X-ray 사진에서 다양한 양상의 음영이 보입니다. 깨끗해야 할 폐 부위에 희미한 그림자가 관찰되는 것입니다. 하지만, 실제 영상을 보면, 희미한 케이스가 많으므로 그 희미함이 폐렴에 의한 것인지, 다른 이유인지는 파악하기 어렵습니다.</p>

<p><img src="https://raw.githubusercontent.com/Nega0619/typora_img/main/img/image-20220203115504878.png?token=ATH7GGLUUYXWQH56TO6YX6LB7NCEQ" alt="image-20220203115504878" /></p>

<p>왼쪽은 정상, 중간은 세균성 폐렴, 오른쪽은 바이러스 폐렴입니다.</p>

<p>세균성 폐렴은 일반적으로 왼쪽 상부 엽(하얀 화살표)에 하얀 부분이 관찰되며, 바이러스성 폐렴은 확산된 “interstitial(조직 사이에 있는)” 패턴으로 나타납니다.</p>

<h1 id="2-의료-영상-데이터-처리하기">2. 의료 영상 데이터 처리하기</h1>

<p>실습 코드는 아래 URL에서 확인하실 수 있으며, 포스팅에는 제가 정확도를 향상시키기 위하여 사용한 아이디어 혹은 새로 배운점 위주로 작성하였습니다.</p>

<h3 id="2-1-inbalance한-데이터를-학습할-때-주의점">2-1. inbalance한 데이터를 학습할 때 주의점</h3>

<h3 id="inbalance한-데이터란">inbalance한 데이터란?</h3>

<p>해당 코드글에서 보실 수 있겠지만, 캐글 폐렴 환자 데이터에서</p>

<h4 id="train-data">train data</h4>

<p>CNN 모델의 경우, 데이터가 클래스 별 balance가 좋을 수록 train을 잘 합니다. 그렇기 때문에  imbalance 문제를 꼭 해결해 주어야합니다.</p>

<h4 id="test-data">test data</h4>

<p>test 데이터는 평가 하기 위해서 사용하기 때문에 학습과 관련이 없어서 inbalance한 데이터 셋이어도 상관없습니다.</p>

<h4 id="validation-data">validation data</h4>

<p>validation 데이터는 평가 하기 위해서 사용하기 때문에 학습과 관련이 없어서 inbalance한 데이터 셋이어도 상관없습니다.</p>

<h3 id="inbalance한-데이터-처리-방법">inbalance한 데이터 처리 방법</h3>

<h4 id="weight-balancing-테크닉-사용">Weight balancing 테크닉 사용</h4>

<p>Weight balancing 은 training set의 각 데이터에서 loss를 계산할 때 특정 클래스의 데이터에 더 큰 loss 값을 갖도록 가중치를 부여하는 방법입니다. Keras는 model.fit()을 호출할 때 파라미터로 넘기는 class_weight 에 이러한 클래스별 가중치를 세팅할 수 있도록 지원하고 있습니다.</p>

<hr />

<p>참고 링크</p>

<p>딥러닝에서 클래스 불균형을 다루는 방법 : https://3months.tistory.com/414</p>

<hr />

<h2 id="2-2-새로-배운-코드">2-2. 새로 배운 코드</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_filenames</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">gfile</span><span class="p">.</span><span class="n">glob</span><span class="p">(</span><span class="n">TRAIN_PATH</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Normal image path</span><span class="se">\n</span><span class="si">{</span><span class="n">filenames</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Pneumonia image path</span><span class="se">\n</span><span class="si">{</span><span class="n">filenames</span><span class="p">[</span><span class="mi">2000</span><span class="p">]</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_list_ds</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">train_filenames</span><span class="p">)</span>
<span class="n">val_list_ds</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">val_filenames</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Train 데이터셋, validation 데이터셋 개수 확인을 해보겠습니다.
</span>
<span class="n">TRAIN_IMG_COUNT</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">cardinality</span><span class="p">(</span><span class="n">train_list_ds</span><span class="p">).</span><span class="n">numpy</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Training images count: </span><span class="si">{</span><span class="n">TRAIN_IMG_COUNT</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="n">VAL_IMG_COUNT</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">cardinality</span><span class="p">(</span><span class="n">val_list_ds</span><span class="p">).</span><span class="n">numpy</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Validating images count: </span><span class="si">{</span><span class="n">VAL_IMG_COUNT</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_ds</span> <span class="o">=</span> <span class="n">train_list_ds</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="n">process_path</span><span class="p">,</span> <span class="n">num_parallel_calls</span><span class="o">=</span><span class="n">AUTOTUNE</span><span class="p">)</span>
<span class="n">val_ds</span> <span class="o">=</span> <span class="n">val_list_ds</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="n">process_path</span><span class="p">,</span> <span class="n">num_parallel_calls</span><span class="o">=</span><span class="n">AUTOTUNE</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">prepare_for_training</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="n">shuffle_buffer_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">shuffle_buffer_size</span><span class="p">)</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="p">.</span><span class="n">repeat</span><span class="p">()</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="p">.</span><span class="n">batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="p">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">AUTOTUNE</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ds</span>

<span class="n">train_ds</span> <span class="o">=</span> <span class="n">prepare_for_training</span><span class="p">(</span><span class="n">train_ds</span><span class="p">)</span>
<span class="n">val_ds</span> <span class="o">=</span> <span class="n">prepare_for_training</span><span class="p">(</span><span class="n">val_ds</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">conv_block</span><span class="p">(</span><span class="n">filters</span><span class="p">):</span>
    <span class="n">block</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">([</span>
        <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">SeparableConv2D</span><span class="p">(</span><span class="n">filters</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">),</span>
        <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">SeparableConv2D</span><span class="p">(</span><span class="n">filters</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">),</span>
        <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
        <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPool2D</span><span class="p">()</span>
    <span class="p">])</span>
    
    <span class="k">return</span> <span class="n">block</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">augment</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">label</span><span class="p">):</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="n">random_flip_left_right</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>  <span class="c1"># 랜덤하게 좌우를 반전합니다.
</span>    <span class="k">return</span> <span class="n">image</span><span class="p">,</span><span class="n">label</span>

<span class="k">def</span> <span class="nf">prepare_for_training</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="n">shuffle_buffer_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="c1"># augment 적용 부분이 배치처리 함수에 추가되었습니다.
</span>    <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span>
            <span class="n">augment</span><span class="p">,</span>       <span class="c1"># augment 함수 적용
</span>            <span class="n">num_parallel_calls</span><span class="o">=</span><span class="mi">2</span>
        <span class="p">)</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">shuffle_buffer_size</span><span class="p">)</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="p">.</span><span class="n">repeat</span><span class="p">()</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="p">.</span><span class="n">batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="p">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">AUTOTUNE</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">ds</span>
</code></pre></div></div>

<p>저 9-7에서 augment 함수 궁금한게.. 저 함수만 입력해도 훈련데이터가 늘어나는 건가요? 아니면 따로 데이터 합치는 코드를 써야하나요?</p>

<p>이래저래 시도했을 때 제가 지금까지 내린 결론은 1) 데이터 양은 계속 동일한데, 2) random하게 flip해주는 걸 추가하고, 3) 덧붙여 repeat()이란 걸 붙여놓으면, 4) 데이터 개수가 무한개로 많아지는데 그 중에 flipped된 종류가 생긴다 인 것 같아요</p>

<p>음… ㅋㅋ 일단 좌우로 flip하는 게 성능 향상에 도움을 준다는 의견이 있긴 해서 한번 따라보겠습니다…ㅋㅋ https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/discussion/66130</p>

<h2 id="2-3-batch-normalization과-dropout을-같이-써도-되는가-안되는가">2-3. Batch Normalization과 Dropout을 같이 써도 되는가? 안되는가?</h2>

<hr />

<p>참고 논문 1.</p>

<p>Understanding the Disharmony between Dropout and Batch Normalization by Variance Shift</p>

<ul>
  <li>chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/viewer.html?pdfurl=https%3A%2F%2Fopenaccess.thecvf.com%2Fcontent_CVPR_2019%2Fpapers%2FLi_Understanding_the_Disharmony_Between_Dropout_and_Batch_Normalization_by_Variance_CVPR_2019_paper.pdf&amp;clen=1272425&amp;chunk=true</li>
</ul>

<p>참고 논문 2.</p>

<p>Rethinking the Usage of Batch Normalization and Dropout in the Training of Deep</p>

<ul>
  <li>chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/viewer.html?pdfurl=https%3A%2F%2Farxiv.org%2Fpdf%2F1905.05928.pdf&amp;clen=856720&amp;chunk=true</li>
</ul>

<hr />

<hr />

<h6 id="출처">출처</h6>

<ul>
  <li>
    <p>AIFFEL LMS</p>

    <p>문제시 연락 부탁드립니다. :)</p>
  </li>
</ul>]]></content><author><name>Armando Maynez</name></author><summary type="html"><![CDATA[해당 포스팅은, 아이펠 Exploration 9번 노드를 학습하고 작성한 기록물 입니다.]]></summary></entry><entry><title type="html">Aiffel 6주차 ) 잘 하고 있는건가</title><link href="http://localhost:4000/AIFFEL-6%EC%A3%BC%EC%B0%A8-)-%EC%9E%98-%ED%95%98%EA%B3%A0-%EC%9E%88%EB%8A%94%EA%B1%B4%EA%B0%80.html" rel="alternate" type="text/html" title="Aiffel 6주차 ) 잘 하고 있는건가" /><published>2022-02-01T00:00:00+09:00</published><updated>2022-02-01T00:00:00+09:00</updated><id>http://localhost:4000/AIFFEL%206%EC%A3%BC%EC%B0%A8%20)%20%EC%9E%98%20%ED%95%98%EA%B3%A0%20%EC%9E%88%EB%8A%94%EA%B1%B4%EA%B0%80</id><content type="html" xml:base="http://localhost:4000/AIFFEL-6%EC%A3%BC%EC%B0%A8-)-%EC%9E%98-%ED%95%98%EA%B3%A0-%EC%9E%88%EB%8A%94%EA%B1%B4%EA%B0%80.html"><![CDATA[<p>오늘은 황금같은 설날 당일.</p>

<p>정말 황금보다 귀했던 것이 처리하고 싶은 작업이 정말 많았기 때문이다.</p>

<p>아이펠을 시작하고 끝없는 욕심에 욕심을 부려왔다. 내가 배워야 할 것도 정말 많았고, 배우고 싶은것도 많았다. 매주 노드 프로젝트도 진행하고 있었고, 봐야 할 강의, 보고싶은 강의는 늘어갔다. 그저 시청으로 끝나지 않고 그 강의의 정리, 발표준비도 해야했다. 그리고 그 과정에서 알게되는 모든 지식들은 다 소중해서 내 발자취 글로 남기고 싶었다. 그렇게 할 일 리스트는 하나 둘 쌓여갔다. 어느새 잠깐의 쉼도 아까울정도로.</p>

<p>오늘은 주말부터 설 당일 까지 4일째 연휴. <del>이제 오늘내일 하루남았다..</del></p>

<p>집안일 하는 시간을 빼면 전부 컴퓨터 앞에 앉아 조사하고, 강의를 보며 계속 혼자서 공부했다. 본가도 가지않고서 혼자서.</p>

<p>맘 놓고 논 적없이 많은 지식들을 습득했고 또 많은 지식들이 스쳐지나갓을텐데 그 지식들은 어디로 갔는지,, exploration node는 손도 댈 수 없었다. 어떻게 모델을 발전시켜야 할 지 어디서부터 손을 대야할지 모를 그 막막함에 멍 때리다가 ㅊㅅㅇ 퍼실님이 게더에 들어오셨다. 그리고 이 황금연휴에 공부하러 오신 수연님을 붙잡고 다짜고짜 고민을 토로했다. ㅋㅋㅋㅋ</p>

<p>.</p>

<p>.</p>

<p>.</p>

<p>프로젝트를 개선할 방법을 어디서 찾을 수 있을지를 고민하고 있고, 점점 exploration node가 막막해진다고 말씀드렸더니, 내가 이런 생각을 하고 있을지 몰랐단다. 내 exploration node들을 보고 있으면 고민을 많이 했다는 것이 느껴지고, 최대한 내 생각을 담아 프로젝트를 진행해보려 했다는 것이 보여서 노력하고 있다는 것을 느끼셨다고 한다. <del>이렇게 하면 많이 힘드시긴 하겠다. 라는 생각도 하셨대요 ㅋㅋㅋ</del></p>

<p>ㅍㅎㅎㅎ 지금 생각해도 기분 좋은 말이다. 점차 난이도는 올라가는데, 그걸 해결할 지식은 점점 내 수준을 벗어나고 있다고 느꼈기 때문이다. 나름 고민했지만 너무 미약한 변화란 생각이 들어 좌절했던 순간들에 보상을 받은 기분이었다.</p>

<p>물론 프로젝트를 개선할 방법에 대한 방법 의논도 해주셨지만 저 한마디가 나의 모든 막막함과 답답함을 해결해주었다. 내가 정말 힘들었던 것은 프로젝트 개선 계획이 서는게 아니라 내가 잘 하고 있다는 믿음, 정체되지 않고 나아가고 있는지가 불안했던것 같다.</p>

<p>고민을 토로해보는게 정말 큰 힘이 되는 것같다. ㅅㅇ님 감사해요! 덕분에 또 앞으로 열심히 할 용기가 생겼습니다!</p>]]></content><author><name>Armando Maynez</name></author><summary type="html"><![CDATA[오늘은 황금같은 설날 당일.]]></summary></entry><entry><title type="html">[ex_07] 인물 사진 만들어보기</title><link href="http://localhost:4000/ex_07-%EC%9D%B8%EB%AC%BC-%EC%82%AC%EC%A7%84-%EB%A7%8C%EB%93%A4%EC%96%B4%EB%B3%B4%EA%B8%B0.html" rel="alternate" type="text/html" title="[ex_07] 인물 사진 만들어보기" /><published>2022-02-01T00:00:00+09:00</published><updated>2022-02-01T00:00:00+09:00</updated><id>http://localhost:4000/%5Bex_07%5D%20%EC%9D%B8%EB%AC%BC%20%EC%82%AC%EC%A7%84%20%EB%A7%8C%EB%93%A4%EC%96%B4%EB%B3%B4%EA%B8%B0</id><content type="html" xml:base="http://localhost:4000/ex_07-%EC%9D%B8%EB%AC%BC-%EC%82%AC%EC%A7%84-%EB%A7%8C%EB%93%A4%EC%96%B4%EB%B3%B4%EA%B8%B0.html"><![CDATA[<p>이번 글에서는 아이펠 Exploration node 7번, 인물 사진을 만들어보자</p>

<hr />

<h6 id="출처">출처</h6>

<ul>
  <li>
    <p>AIFFEL LMS</p>

    <p>문제시 연락 부탁드립니다. :)</p>
  </li>
  <li>
    <p>5</p>
  </li>
</ul>]]></content><author><name>Armando Maynez</name></author><summary type="html"><![CDATA[이번 글에서는 아이펠 Exploration node 7번, 인물 사진을 만들어보자]]></summary></entry><entry><title type="html">Cs231 ) 5강 convolution neural networks</title><link href="http://localhost:4000/CS231-)-5%EA%B0%95-Convolution-Neural-Networks.html" rel="alternate" type="text/html" title="Cs231 ) 5강 convolution neural networks" /><published>2022-02-01T00:00:00+09:00</published><updated>2022-02-01T00:00:00+09:00</updated><id>http://localhost:4000/CS231%20)%205%EA%B0%95%20Convolution%20Neural%20Networks</id><content type="html" xml:base="http://localhost:4000/CS231-)-5%EA%B0%95-Convolution-Neural-Networks.html"><![CDATA[<p>이번 포스팅에서는 stanford university의 CS231 강의를 보고 이해한 내용을 정리해 보았습니다.</p>]]></content><author><name>Armando Maynez</name></author><summary type="html"><![CDATA[이번 포스팅에서는 stanford university의 CS231 강의를 보고 이해한 내용을 정리해 보았습니다.]]></summary></entry><entry><title type="html">Cs231 ) 4강 introduction to neural networks</title><link href="http://localhost:4000/CS231-)-4%EA%B0%95-Introduction-to-Neural-Networks.html" rel="alternate" type="text/html" title="Cs231 ) 4강 introduction to neural networks" /><published>2022-02-01T00:00:00+09:00</published><updated>2022-02-01T00:00:00+09:00</updated><id>http://localhost:4000/CS231%20)%204%EA%B0%95%20Introduction%20to%20Neural%20Networks</id><content type="html" xml:base="http://localhost:4000/CS231-)-4%EA%B0%95-Introduction-to-Neural-Networks.html"><![CDATA[<p>이번 포스팅에서는 stanford university의 CS231 강의를 보고 이해한 내용을 정리해 보았습니다.</p>]]></content><author><name>Armando Maynez</name></author><summary type="html"><![CDATA[이번 포스팅에서는 stanford university의 CS231 강의를 보고 이해한 내용을 정리해 보았습니다.]]></summary></entry></feed>