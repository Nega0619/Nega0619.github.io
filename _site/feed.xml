<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-02-21T02:22:36+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Hwi’s footsteps</title><subtitle>Artificial Intelligence trends and concepts made easy.</subtitle><author><name>Armando Maynez</name></author><entry><title type="html">20220212 추천 시스템 세미나</title><link href="http://localhost:4000/20220212-%EC%B6%94%EC%B2%9C-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%84%B8%EB%AF%B8%EB%82%98.html" rel="alternate" type="text/html" title="20220212 추천 시스템 세미나" /><published>2022-02-12T00:00:00+09:00</published><updated>2022-02-12T00:00:00+09:00</updated><id>http://localhost:4000/20220212%20%EC%B6%94%EC%B2%9C%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%B8%EB%AF%B8%EB%82%98</id><content type="html" xml:base="http://localhost:4000/20220212-%EC%B6%94%EC%B2%9C-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%84%B8%EB%AF%B8%EB%82%98.html"><![CDATA[<h1 id="explore">Explore</h1>

<h2 id="좋은-논문-찾는-방법">좋은 논문 찾는 방법</h2>

<ul>
  <li>키워드로 찾기
    <ul>
      <li>google scholar 키워드로 검색</li>
    </ul>
  </li>
  <li>학회에서 찾기
    <ul>
      <li>Top-tier Conference 세계 최고 권위 학회에서 찾기</li>
    </ul>
  </li>
  <li>논문의 저자로 찾기
    <ul>
      <li>유명 논문의 저자 혹은 연구 그룹</li>
    </ul>
  </li>
</ul>

<h3 id="키워드란">키워드란?</h3>

<ul>
  <li>기술 키워드
    <ul>
      <li>추천 시스템의 경우
        <ul>
          <li>deep learning + recommender systems</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>도메인 키워드
    <ul>
      <li>원하는 분야가 있는 경우
        <ul>
          <li>music + recommender system</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>처음 입문 하는경우
    <ul>
      <li>survey 혹은 review로 검색!</li>
    </ul>
  </li>
  <li>연구 주제를 보는 방법
    <ul>
      <li>연구단체 홈페이지를 가면 연구 주제 목록이있습니다.</li>
    </ul>
  </li>
  <li>요즘 학한 키워드를 찾는 법
    <ul>
      <li>학회 + 연도 + accepted paers로 구글에 검색</li>
    </ul>
  </li>
</ul>

<h3 id="세계-최고-권위-학회-저널">세계 최고 권위 학회 저널</h3>

<p><img src="../assets/img/posts/image-20220212141355656.png" alt="image-20220212141355656" /></p>

<ul>
  <li>
    <p>밑에는 주제별 유명 학회입니다.</p>
  </li>
  <li>h5 인덱스 값이란?
    <ul>
      <li>최근 5년간 n번 이상 인용된 논문이 n개</li>
    </ul>
  </li>
  <li>Impact Factor IF
    <ul>
      <li>최근 2년간 평균 인용 수</li>
    </ul>
  </li>
  <li>Acceptance rate</li>
</ul>

<p><img src="../assets/img/posts/image-20220212141835733.png" alt="image-20220212141835733" /></p>

<p><img src="../assets/img/posts/image-20220212141910175.png" alt="image-20220212141910175" /></p>

<ul>
  <li>저기 링크는 학회별 논문에 대해 꾸준히 업뎃중임</li>
</ul>

<h3 id="저자-또는-연구-그룹">저자 또는 연구 그룹</h3>

<p>저자의 관심 키워드 Research Interest를 찾기!</p>

<p><img src="../assets/img/posts/image-20220212142000850.png" alt="image-20220212142000850" /></p>

<p>구글 스칼라에 label해서 검색하면 프로필이 뜹니다. 유명한 저자가 나온다고합니다.</p>

<p><img src="../assets/img/posts/image-20220212142221965.png" alt="image-20220212142221965" /></p>

<h2 id="논문은-어떻게-읽어야-할까요">논문은 어떻게 읽어야 할까요?</h2>

<p>꼭 순서대로 읽어야 할필요도, 사람마다 다 다르니, 논문의 구조를 먼저 알려줄예정입니다.</p>

<p><img src="../assets/img/posts/image-20220212142930257.png" alt="image-20220212142930257" /></p>

<ul>
  <li>제목</li>
  <li>저자 및 소속
    <ul>
      <li>논문에 대해 질문이나 잘못된거나 코드 요청등을 하는 곳은 corresponding Author</li>
    </ul>
  </li>
  <li>abstract</li>
  <li>introduction 서론</li>
</ul>

<p><img src="../assets/img/posts/image-20220212143555507.png" alt="image-20220212143555507" /></p>

<ol>
  <li>Introduction</li>
</ol>

<ul>
  <li>figure (그림)
    <ul>
      <li>그림 바로 밑에 혹은 본문 내용에 적혀져있음.</li>
    </ul>
  </li>
  <li>contributions (기여)</li>
</ul>

<ol>
  <li>Methodology (방법론)</li>
</ol>

<ul>
  <li>수식을 많으면 많을 수록 좋다,,</li>
</ul>

<p><img src="../assets/img/posts/image-20220212143920087.png" alt="image-20220212143920087" /></p>

<ol>
  <li>related work( 관련 연구 )</li>
</ol>

<ul>
  <li>과거의 연구를 어디까지 봐야하는지를 알 수 있는 부분.</li>
</ul>

<p><img src="../assets/img/posts/image-20220212144044156.png" alt="image-20220212144044156" /></p>

<ul>
  <li>RQ와 실험결과는 이어집니다.</li>
</ul>

<p><img src="../assets/img/posts/image-20220212144204575.png" alt="image-20220212144204575" /></p>

<p><img src="../assets/img/posts/image-20220212144319488.png" alt="image-20220212144319488" /></p>

<p><img src="../assets/img/posts/image-20220212144507901.png" alt="image-20220212144507901" /></p>

<ul>
  <li>타고 타고 올라가 볼 논문들이 나와있는 경우가 많습니다.</li>
</ul>

<h2 id="논문-어떻게-정리해야-할까요">논문 어떻게 정리해야 할까요?</h2>

<h3 id="논문-관리-툴">논문 관리 툴</h3>

<ul>
  <li>End note www.endnote.com</li>
  <li>Mendeley www.mendeley.com</li>
</ul>

<h2 id="논문을-어떻게-구현을-해야할까요">논문을 어떻게 구현을 해야할까요</h2>

<ul>
  <li>논문 구현체 찾기
    <ul>
      <li>크롬 extension중에 뭐를 설치하면 구글 스칼라에서 아래 사진 왼쪽 그림처럼 코드가 있으면 있다고 뜨는게 있습니다.
        <ul>
          <li>https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil</li>
          <li>AI/ML Papers with Code Everywhere - CatalyzeX</li>
        </ul>
      </li>
      <li>저자에게 요청 혹은 직접 구현 (정중하고 연구목적 , 관심있다는 얘기로. ㅇㅇ)</li>
      <li><img src="../assets/img/posts/image-20220212145213331.png" alt="image-20220212145213331" /></li>
    </ul>
  </li>
</ul>

<h2 id="논문-작성-순서">논문 작성 순서</h2>

<p><img src="../assets/img/posts/image-20220212145455865.png" alt="image-20220212145455865" /></p>

<p><img src="../assets/img/posts/image-20220212145807825.png" alt="image-20220212145807825" /></p>

<h1 id="exploit">Exploit</h1>]]></content><author><name>Armando Maynez</name></author><summary type="html"><![CDATA[Explore]]></summary></entry><entry><title type="html">[fd_18] 딥러닝 들여다보기</title><link href="http://localhost:4000/fd_18-%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%93%A4%EC%97%AC%EB%8B%A4%EB%B3%B4%EA%B8%B0.html" rel="alternate" type="text/html" title="[fd_18] 딥러닝 들여다보기" /><published>2022-02-08T00:00:00+09:00</published><updated>2022-02-08T00:00:00+09:00</updated><id>http://localhost:4000/%5Bfd_18%5D%20%20%EB%94%A5%EB%9F%AC%EB%8B%9D%20%EB%93%A4%EC%97%AC%EB%8B%A4%EB%B3%B4%EA%B8%B0</id><content type="html" xml:base="http://localhost:4000/fd_18-%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%93%A4%EC%97%AC%EB%8B%A4%EB%B3%B4%EA%B8%B0.html"><![CDATA[<p>이 포스팅은 아이펠 fundamentals 18번 노드를 학습하고 적은 기록물 입니다.</p>

<h1 id="신경망이란">신경망이란?</h1>

<p>과학자들은 문제에 대한 해답을 종종 자연에서 찾아냅니다. 머신러닝 / 딥러닝 과학자들은 해당 문제를 해결하기 위하여 신경망의 뉴런 하나를 본 딴, 퍼셉트론의 개념을 도입하였고, 후에 이를 연결하여 다층 신경망 구조, 인공신경망을 구축해내게 됩니다.</p>

<p>신경망은 모두가 가지고 있는 뇌의 뉴런들을 본딴 것입니다. 뉴런들이 모여 거대한 그물망과 같은 형태를 띄고 있는데, 이를 컴퓨터 프로그램으로 풀어낸 것입니다.</p>

<p>다음은 다층 퍼셉트론 구조로 학습한 mnist 코드의 부분입니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 모델에 맞게 데이터 가공
</span><span class="n">x_train_norm</span><span class="p">,</span> <span class="n">x_test_norm</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">/</span> <span class="mf">255.0</span>
<span class="n">x_train_reshaped</span> <span class="o">=</span> <span class="n">x_train_norm</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">x_train_norm</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">x_train_norm</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">x_test_reshaped</span> <span class="o">=</span> <span class="n">x_test_norm</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">x_test_norm</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">x_test_norm</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

<span class="c1"># 딥러닝 모델 구성 - 2 Layer Perceptron
</span><span class="n">model</span><span class="o">=</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">784</span><span class="p">,)))</span>  <span class="c1"># 입력층 d=784, 은닉층 레이어 H=50
</span><span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">))</span>   <span class="c1"># 출력층 레이어 K=10
</span><span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>

</code></pre></div></div>

<p>궁금증 1. x_train_reshaped에서 왜 -1 값을 줄까?</p>

<p>​	찾아보니 reshape에서 (-1) 옵션을 주면, 주어진 옵션값에 맞는 값을 찾아준다고 한다.</p>

<p>궁금증 2. 전에 Dense()는 뭐였을까 궁금했었다.</p>

<p>​	Dense : 다층 퍼셉트론을 keras 코드로 사용하는 거였습니다.</p>

<h1 id="bias란">Bias란?</h1>

<p>bias에 관한 링크를 보다 궁금증이 생겼었습니다.</p>

<p>참고 링크 : https://stackoverflow.com/questions/2480650/what-is-the-role-of-the-bias-in-neural-networks</p>

<p>질문 1. 제가 알고 있는 출력값 y = w(가중치)*x(입력데이터) + b(bias)인데, 링크의 첫번째 답변에서 bias를 이용한 시그모이드를 sigmoid(w0*x + w1*1.0)이라 표현했어요. 제가 알기론 bias에 관해서는 가중치를 안쓴다고 알고있는데 쓰는경우도 있는건지, 원래 쓰는데 안쓰는걸로 제가 잘못알고있는건지 궁금해요.</p>

<ul>
  <li>
    <p>이 질문에 가장 도움이 되었던 링크 두개를 먼저 첨부합니다.</p>

    <ul>
      <li>https://devlog.jwgo.kr/2018/04/16/sigmoid-graph-according-to-slope-change/</li>
      <li>https://blog.naver.com/PostView.nhn?blogId=winddori2002&amp;logNo=221937861519</li>
    </ul>
  </li>
  <li>
    <p>가장 먼저 이해가 안됐던 부분은 bias가 성공적인 학습에 매우 중요한 요소이며, bias가 바뀜에 따라 함수가 왼쪽 혹은 오른쪽으로 이동이 된다는 것이었습니다. 제가 알고있는 출력 함수의 식은 <code class="language-plaintext highlighter-rouge">w*x + b</code>인데, 결국 w가 0일때 활성화함수가 b인곳을 꼭 지나게 됩니다. w=0일때, bias값의 절편에 따라 출력함수값이 거기에 묶이게 되는데 어떻게 성공적인 학습에 어떻게 기여를 하는지가 이해가 안됐고 특히 bias값에 따라 그래프가 왼쪽 혹은 오른쪽으로 움직이는 것이 아니라 위 아래로 움직여야 한다고생각했습니다.</p>

    <ul>
      <li>
        <p>이 질문이 들었던 가장 큰 오해는 출력함수는 wx+b라는 가장 간단한 식으로 나타내는것이 아니라는 것입니다. 예를 들어, sigmoid함수에서 wx+b함수를 적용해서 그리면 아래 링크와 같습니다.</p>

        <p>https://devlog.jwgo.kr/2018/04/16/sigmoid-graph-according-to-slope-change/</p>
      </li>
      <li>
        <p>bias를 -10에서 10으로 변화시킬때 시그모이드 함수의 형태를 보여주고 있습니다. 세로가 아니라 가로로 움직이게 된다는 것을 시각적으로 확인하였고, wx+b에서 학습결과가 꼭 0, b를 지나게되지 않는다는 것도 이해를 하게되었습니다.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>두번째로 이해가 안되었던, 시그모이드에서 bias 1.0을 sigmoid(w0*x + w1*1.0)과 같이 가중치가 있는것 처럼 표현하였습니다. 이부분은 아래 질문에서 답하겠습니다.</p>
  </li>
</ul>

<p>질문2. bias에 관해서 그렇게 깊게 생각해보지 않았었는데, (그냥 주는구나 싶은정도?) bias 값은 어떻게 결정해서 주게되나용? 이거도 그냥 많이 쓰는숫자에서 시행착오로 돌려보고 결정하나요?</p>

<ul>
  <li>
    <p>https://brunch.co.kr/@coolmindory/32</p>

    <p>여기 링크를 보고 이해가 되었습니다. 여기서 보면 backpropagation에서 업데이트 대상은 가중치와 bias 둘 다입니다. 그랬기 때문에, 바이어스에도 가중치가 있다는 듯이 표현을 한것이라 이해했습니다.</p>

    <p>그리고 최근에 backpropagation에 대해서 발표를 한 적이 있는데, 그때 이런 질문을 받은 적이 있습니다. 그렇다면 Backpropagation에서 bias는 어떻게 업데이트되냐 라는 질문이었습니다. 저는 그때 출력함수 wx+b라는 매우 간단한 식만을 이해하고 있었기 때문에, backpropagation에서 b는 상수항이다. 그래서, 미분하면 0이 된다. 라고 답변을 드렸었는데, 제가 잘못된 답변을 드린것을 알게되었습니다. 가중치를 갱신할 때 w=w-α*dL/dw 인것처럼 bias도 b= b-α*dL/db로 갱신된다는 것을 알게 되었습니다.</p>
  </li>
</ul>

<h1 id="활성화-함수">활성화 함수</h1>

<p>신경망은 수 많은 뉴런으로 이루어져 있고,</p>

<h1 id="손실함수">손실함수</h1>

<h1 id="경사하강법">경사하강법</h1>

<h1 id="오늘-배운-메소드">오늘 배운 메소드</h1>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">np.dot(X,Y)</code> : np.array 객체를 곱할때 사용합니다.</p>

    <ul>
      <li>
        <p>1차원 행렬(Vector) 이라면 : 각 자리 숫자끼리 곱하여 더합니다.</p>
      </li>
      <li>
        <p>2차원 행렬(matrix) 라면 : 일반적인 행렬 곱을 수행합니다.</p>

        <p><img src="../../../../Typora Images/image-20220121215051856.png" alt="image-20220121215051856" /></p>

        <p>출처 : https://ko.wikipedia.org/wiki/%ED%96%89%EB%A0%AC_%EA%B3%B1%EC%85%88</p>
      </li>
      <li>
        <p>X나 Y 중 하나가 상수라면 : 상수곱 연산을 합니다.</p>
      </li>
    </ul>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">np.exp(x)</code> : numpy.exp() 함수는 밑이 자연상수 e인 지수함수(e^x)로 변환해줍니다.</p>
  </li>
</ul>

<hr />

<h6 id="출처">출처</h6>

<ul>
  <li>
    <p>AIFFEL LMS</p>

    <p>문제시 연락 부탁드립니다. :)</p>
  </li>
  <li>
    <p>https://m.blog.naver.com/shwotjd14/221435180635</p>
  </li>
  <li>
    <p>https://reniew.github.io/12/</p>
  </li>
</ul>]]></content><author><name>Armando Maynez</name></author><summary type="html"><![CDATA[이 포스팅은 아이펠 fundamentals 18번 노드를 학습하고 적은 기록물 입니다.]]></summary></entry><entry><title type="html">머신러닝 ) 앙상블 ensemble</title><link href="http://localhost:4000/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-)-%EC%95%99%EC%83%81%EB%B8%94-Ensemble.html" rel="alternate" type="text/html" title="머신러닝 ) 앙상블 ensemble" /><published>2022-02-08T00:00:00+09:00</published><updated>2022-02-08T00:00:00+09:00</updated><id>http://localhost:4000/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%20)%20%EC%95%99%EC%83%81%EB%B8%94%20Ensemble</id><content type="html" xml:base="http://localhost:4000/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-)-%EC%95%99%EC%83%81%EB%B8%94-Ensemble.html"><![CDATA[<p>Kaggle 사이트에서</p>

<hr />

<h6 id="출처">출처</h6>

<ul>
  <li>
    <p>Introduction to Ensemble Learning</p>

    <p>https://subinium.github.io/introduction-to-ensemble-1/#:~:text=%EC%95%99%EC%83%81%EB%B8%94(Ensemble)%20%ED%95%99%EC%8A%B5%EC%9D%80%20%EC%97%AC%EB%9F%AC,%EB%A5%BC%20%EA%B0%80%EC%A7%80%EA%B3%A0%20%EC%9D%B4%ED%95%B4%ED%95%98%EB%A9%B4%20%EC%A2%8B%EC%8A%B5%EB%8B%88%EB%8B%A4.</p>
  </li>
  <li>
    <p>Kaggle Ensembling Guide 한글 번역</p>

    <p>https://jamm-notnull.tistory.com/16</p>

    <p>ㅎ</p>
  </li>
</ul>]]></content><author><name>Armando Maynez</name></author><summary type="html"><![CDATA[Kaggle 사이트에서]]></summary></entry><entry><title type="html">머신러닝 ) 다변량회귀분석 multivariate regression</title><link href="http://localhost:4000/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-)-%EB%8B%A4%EB%B3%80%EB%9F%89%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D-Multivariate-regression.html" rel="alternate" type="text/html" title="머신러닝 ) 다변량회귀분석 multivariate regression" /><published>2022-02-08T00:00:00+09:00</published><updated>2022-02-08T00:00:00+09:00</updated><id>http://localhost:4000/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%20)%20%EB%8B%A4%EB%B3%80%EB%9F%89%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D%20Multivariate%20regression</id><content type="html" xml:base="http://localhost:4000/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-)-%EB%8B%A4%EB%B3%80%EB%9F%89%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D-Multivariate-regression.html"><![CDATA[<p>fundamental 노드 19번을 공부할 때, 아이펠에서 나왔던 질문을 바탕으로 공부했던 것을 작성해보고자 합니다.</p>

<hr />

<h6 id="출처">출처</h6>

<ul>
  <li>https://techblog-history-younghunjo1.tistory.com/118</li>
</ul>]]></content><author><name>Armando Maynez</name></author><summary type="html"><![CDATA[fundamental 노드 19번을 공부할 때, 아이펠에서 나왔던 질문을 바탕으로 공부했던 것을 작성해보고자 합니다.]]></summary></entry><entry><title type="html">동적 웹 페이지와 정적 웹 페이지</title><link href="http://localhost:4000/%EB%8F%99%EC%A0%81-%EC%9B%B9-%ED%8E%98%EC%9D%B4%EC%A7%80%EC%99%80-%EC%A0%95%EC%A0%81-%EC%9B%B9-%ED%8E%98%EC%9D%B4%EC%A7%80.html" rel="alternate" type="text/html" title="동적 웹 페이지와 정적 웹 페이지" /><published>2022-02-08T00:00:00+09:00</published><updated>2022-02-08T00:00:00+09:00</updated><id>http://localhost:4000/%EB%8F%99%EC%A0%81%20%EC%9B%B9%20%ED%8E%98%EC%9D%B4%EC%A7%80%EC%99%80%20%EC%A0%95%EC%A0%81%20%EC%9B%B9%20%ED%8E%98%EC%9D%B4%EC%A7%80</id><content type="html" xml:base="http://localhost:4000/%EB%8F%99%EC%A0%81-%EC%9B%B9-%ED%8E%98%EC%9D%B4%EC%A7%80%EC%99%80-%EC%A0%95%EC%A0%81-%EC%9B%B9-%ED%8E%98%EC%9D%B4%EC%A7%80.html"><![CDATA[<p>https://titus94.tistory.com/4</p>

<ul>
  <li>예시</li>
</ul>

<p>https://hogni.tistory.com/75</p>]]></content><author><name>Armando Maynez</name></author><summary type="html"><![CDATA[https://titus94.tistory.com/4]]></summary></entry><entry><title type="html">Kaggle ) imagenet embeddings 발표자료</title><link href="http://localhost:4000/kaggle-)-Imagenet-embeddings-%EB%B0%9C%ED%91%9C%EC%9E%90%EB%A3%8C.html" rel="alternate" type="text/html" title="Kaggle ) imagenet embeddings 발표자료" /><published>2022-02-08T00:00:00+09:00</published><updated>2022-02-08T00:00:00+09:00</updated><id>http://localhost:4000/kaggle%20)%20Imagenet%20embeddings%20%EB%B0%9C%ED%91%9C%EC%9E%90%EB%A3%8C</id><content type="html" xml:base="http://localhost:4000/kaggle-)-Imagenet-embeddings-%EB%B0%9C%ED%91%9C%EC%9E%90%EB%A3%8C.html"><![CDATA[<p>오늘은 새로 가입한 kaggle 스터디에서 발표준비를 하면서 공부한 내용을 정리해 보았습니다.</p>

<p>주제는 kaggle의 Pawpularity Contest이며,  링크는 다음과 같습니다.</p>

<ul>
  <li>kaggle의 주제 사이트</li>
</ul>

<ul>
  <li>분석할 코드 링크</li>
</ul>

<p>&lt; 목차 &gt;</p>

<ul>
  <li>사전지식
    <ul>
      <li>이미지 임베딩</li>
      <li>Rapids SVR</li>
      <li>Finetuned models</li>
      <li>StatifiedKFold</li>
    </ul>
  </li>
  <li>코드 분석</li>
</ul>

<h3 id="0-소개라-하고-약치기라고-이해한다">0. 소개(라 하고 약치기라고 이해한다)</h3>

<ul>
  <li>아팠음!</li>
  <li>결론 -&gt; 다못했음!</li>
  <li>어차피 다들 코드 한번 본다고 바로 못쓰자나?!(당당) 전 그래요!ㅋㅋㅋㅋ</li>
</ul>

<p>이번 발표의 목표</p>

<ul>
  <li>후에 kaggle이나 익스노드를 진행할 때, 이런 아이디어가 있더라 하는 아이디어만이라도 줍줍해가시면 좋겠습니다 :&gt;</li>
  <li>가끔 보이는 파이썬 기법들 줍줍해가시면 좋겠습니다 map이라던지 lambda라던지.</li>
  <li>코드 이해는 못하셔도 됩니다! 저도 못했거든요^^,,,</li>
</ul>

<p><a href="https://petfinder.my/">PetFinder.my</a> 는 180,000마리 이상의 동물과 54,000마리가 행복하게 입양된 말레이시아 최고의 동물 복지 플랫폼입니다. PetFinder는 동물 애호가, 미디어, 기업 및 글로벌 조직과 긴밀하게 협력하여 동물 복지를 개선합니다.</p>

<p>현재 PetFinder.my는 기본 <a href="https://petfinder.my/cutenessmeter">귀여움 측정기</a> 를 사용하여 애완 동물 사진의 순위를 매깁니다. 수천 개의 애완 동물 프로필의 성능과 비교하여 사진 구성 및 기타 요소를 분석합니다. 이 기본 도구는 유용하지만 아직 실험 단계에 있으며 알고리즘을 개선할 수 있습니다.</p>

<p><img src="D:%5CGithub%5CtistoryPostings%5Cartificial%20Intelligence%5Cimages%5Cpages%5Cimage-20220211190235834.png" alt="image-20220211190235834" /></p>

<p><img src="D:%5CGithub%5CtistoryPostings%5Cartificial%20Intelligence%5Cimages%5Cpages%5Cimage-20220211190315705.png" alt="image-20220211190315705" /></p>

<h1 id="1-이미지-임베딩이란-image-embedding">1. 이미지 임베딩이란? image Embedding</h1>

<h3 id="임베딩-embedding이란">임베딩 Embedding이란?</h3>

<p>머신러닝의 핵심은 데이터에서 패턴을 찾는 것입니다. 머신러닝은 데이터의 특징으로부터 데이터의 패턴을 찾아 유사 데이터를 뽑아내거나 분류합니다. 하지만, <strong>데이터는 우리가 적절한 특징을 찾도록 구조화되지 않는 경우가 많습니다.</strong> 이러한 경우 구조화되있지 않은 데이터의 특징을 나타내는 벡터가 필요한데 이러한 벡터를 <strong><em>임베딩 벡터</em></strong> 라고 부릅니다.</p>

<p><strong>고차원의 정보를 저차원으로 변환하면서 필요한 정보만 임베딩 벡터에 보존하는 것을 임베딩</strong>이라고 합니다. 임베딩 과정을 통해 컴퓨터는 데이터에 대한 저차원 임베딩 벡터를 생산하고 이를 통해 새로운 데이터에 대한 예측을 진행하게 됩니다.</p>

<p>다음 예를 통해 쉽게 이해하실 수 있습니다.</p>

<p><img src="../images/pages/image-20220209112930636.png" alt="image-20220209112930636" /></p>

<p>위와 같이 범주형 데이터가 있다고 할때, ID에는 아무 의미가 없기 때문에 이 데이터를 학습하기 위해선 다른 전처리가 필요합니다. 보통 일반적인 방법은 one-hot-encoding입니다.</p>

<p><img src="../images/pages/image-20220209113257816.png" alt="image-20220209113257816" /></p>

<p>위의 변환된 벡터 값을 이용하여 참치김치찌개와 다른 메뉴 사이의 거리를 계산하면 다음과 같습니다.</p>

<p><img src="../images/pages/image-20220209113310297.png" alt="image-20220209113310297" /></p>

<p>김치찌개 종류가 참치초밥과 된장찌개와는 다를텐데 전부 거리가 같습니다.</p>

<p>이런 경우, 메뉴 추천시스템에서 어제 참치김치찌개를 먹어도 비슷한 생고기 김치찌개를 추천해주게 됩니다.</p>

<p>임베딩을 적용하면 다음과 같습니다. 변환되는 벡터의 차원은 3차원으로 정하고 각각 찌개 강함 정도, 고기 선호도, 건강한 정도를 나타낸다고 합시다.</p>

<p><img src="../images/pages/image-20220209113511472.png" alt="image-20220209113511472" /></p>

<p>참치김치찌개와 다른 메뉴 사이의 거리를 다시 계산해보면 다음과 같습니다.</p>

<p><img src="../images/pages/image-20220209113605829.png" alt="image-20220209113605829" /></p>

<p>복합적인 모든 특성이 통합되어있는 고차원 데이터를 각각의 특성요소를 떼서 저차원 벡터를 만드는 과정을 임베딩이라고 합니다.</p>

<ul>
  <li>https://simonezz.tistory.com/43</li>
  <li>https://velog.io/@dongho5041/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%98-Embedding%EC%9D%B4%EB%9E%80</li>
  <li>임베딩 추천 글 : https://blog.linewalks.com/archives/6408</li>
</ul>

<h3 id="이미지-임베딩">이미지 임베딩</h3>

<p>잡지 표지 이미지를 보고 비슷한 잡지를 찾는다고 가정할 때, pixel-by-pixel로 유사성을 측정하는 것은 의미가 없습니다. 이런 경우, 임베딩을 추출하면 semantic information을 통해 효과적으로 측정할 수 있다.</p>

<h1 id="2-transfer-learning">2. Transfer learning</h1>

<p>많은 사람들이 ML 모델들을 이용해서 고차원이거나 복잡하거나 구조화되지 않은 데이터를 임베딩으로 인코딩하고자한다.</p>

<p>텍스트나 이미지, 그 외 데이터들을 인코딩하기 위해 <strong>미리 트레이닝된 네트워크</strong>를 이용하여 임베딩 시키는 것을 <strong><em>transfer learning</em></strong>이라 한다.</p>

<p>그러므로, <strong>Transfer Learning</strong>을 통해 지식을 재사용할 수 있을 뿐만 아니라, 트레이닝 시키는 시간을 대폭 줄일 수 있다.</p>

<p>임베딩은 모델 다음방법으로 적용가능합니다. <strong>임베딩을 인풋 feature vectors로 사용</strong>하는 것이다. Base input featrues를 미리 트레이닝된 임베딩에 쌓아서 인풋 feature vector를 형성할 수 있다. 키포인트는 이러한 임베딩이 트레이닝이 가능하지 않다는 것이다. 즉, 모델을 트레이닝시킬 때 튜닝되지 않는다.</p>

<p><img src="D:%5CGithub%5CtistoryPostings%5Cartificial%20Intelligence%5Cimages%5Cpages%5Cimage-20220209115041484.png" alt="image-20220209115041484" /></p>

<ul>
  <li>https://simonezz.tistory.com/44</li>
</ul>

<h1 id="3-rapids-svr">3. RAPIDs SVR</h1>

<p>래피즈(Rapids)는 엔비디아에서 개발하고 관리하는 오픈 소스 GPU 가속 데이터 과학 및 머신러닝 라이브러리입니다. Panda, Scikit-learn, numpy 등과 같은 기존의 많은 CPU 도구와 호환되도록 설계되었습니다. 많은 데이터 과학 및 기계 학습 작업을 대규모 가속화할 수 있으며, 종종 100X 또는 그 이상의 비율로 가속화할 수 있는 툴입니다. Rapids는 여전히 개발 중에 있다고 합니다.</p>

<p>https://rapids.ai/</p>

<h1 id="4-finetuned-models">4. Finetuned models</h1>

<ul>
  <li>
    <p>fine tuning이란?</p>

    <p>- <strong>기존에 학습되어져 있는 모델을 기반으로 아키텍쳐를 새로운 목적(나의 이미지 데이터에 맞게)변형하고 이미 학습된 모델 Weights로 부터 학습을 업데이트하는 방법</strong>을 말합니다.</p>
  </li>
  <li>
    <p>예시</p>

    <p>고양이와 개 분류기를 만드는데 다른 데이터로 학습된 모델(VGG16, ResNet 등) 을 가져다 쓰는 경우</p>

    <p>VGG16 모델의 경우 1000 개의 카테고리를 학습시켰기 때문에 고양이와 개, 2개의 카테고리만 필요한 우리 문제를 해결하는데 모든 레이어를 그대로 쓸 수는 없습니다.</p>

    <p>따라서 가장 쉽게 이용하려면 내 데이터를 해당 모델로 예측(predict)하여 보틀넥 피쳐만 뽑아내고, 이를 이용하여 풀리 커넥티드 레이어(Fully-connected layer) 만 학습시켜서 사용하는 방법을 취하면 됩니다.</p>

    <ul>
      <li>보틀넥 피처 : 가장 마지막 CNN 블록을 의미(모델에서 가장 추상화된 피처)하며, Fully connected layer 직전의 CNN블록의 결과를 의미한다.</li>
    </ul>
  </li>
</ul>

<p>출처: https://eehoeskrap.tistory.com/186 [Enough is not enough]</p>

<h1 id="5-stratifiedkfold">5. Stratifiedkfold</h1>

<ul>
  <li>
    <p>k-fold : 학습데이터셋과 검증 데이터 셋을 나누어서 진행하는 것</p>
  </li>
  <li>
    <p>startifiedkfold : 불균형한 dataset일 경우 사용하는 kfold 방법</p>

    <ul>
      <li>
        <p>k개의 fold를 분할한 이후에도 전체 훈련 데이터의 class 비율과 각 fold가 가지고 있는 class 비율을 맞춰줍니다.</p>
      </li>
      <li>
        <p>파라미터</p>

        <p>n_splits : Fold의 개수 k 값 (정수형, 기본 : 5)</p>

        <p>shuffle : 데이터를 쪼갤 때 섞을지 유무 (True/False, 기본 : False)</p>

        <p>random_state : 난수 설정</p>

        <p>https://8888-wpkwtqrc21bbba6iczeu3g152.e.prod.connect.ainize.ai/notebooks/aiffel/Untitled.ipynb</p>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">features</span> <span class="o">=</span> <span class="n">iris</span><span class="p">.</span><span class="n">data</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">iris</span><span class="p">.</span><span class="n">target</span>
<span class="n">dt_clf</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
    
<span class="n">iris_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">iris</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">iris</span><span class="p">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">iris_df</span><span class="p">[</span><span class="s">'label'</span><span class="p">]</span><span class="o">=</span><span class="n">iris</span><span class="p">.</span><span class="n">target</span>
    
<span class="n">skf</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">n_iter</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">val_index</span> <span class="ow">in</span> <span class="n">skf</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">iris_df</span><span class="p">,</span> <span class="n">iris_df</span><span class="p">[</span><span class="s">'label'</span><span class="p">]):</span>
    <span class="k">print</span><span class="p">(</span><span class="n">train_index</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n\n\n</span><span class="s">'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">val_index</span><span class="p">,</span> <span class="s">'</span><span class="se">\n\n\n</span><span class="s">'</span><span class="p">)</span>
    <span class="n">n_iter</span> <span class="o">+=</span> <span class="mi">1</span>
        
    <span class="n">label_train</span> <span class="o">=</span> <span class="n">iris_df</span><span class="p">[</span><span class="s">'label'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">]</span>
    <span class="n">label_val</span> <span class="o">=</span> <span class="n">iris_df</span><span class="p">[</span><span class="s">'label'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="n">val_index</span><span class="p">]</span>
        
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_val</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">features</span><span class="p">[</span><span class="n">val_index</span><span class="p">]</span>
    <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_val</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">labels</span><span class="p">[</span><span class="n">val_index</span><span class="p">]</span>
    <span class="n">dt_clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
        
    <span class="k">print</span><span class="p">(</span><span class="s">'###### cross validation ##### : {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">n_iter</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'교차 검증 정확도 : {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">Y_val</span><span class="p">,</span> <span class="n">dt_clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_val</span><span class="p">))))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'학습 레이블 데이터 분포 </span><span class="se">\n</span><span class="s">'</span><span class="p">,</span> <span class="n">label_train</span><span class="p">.</span><span class="n">value_counts</span><span class="p">())</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'검증 레이블 데이터 분포 </span><span class="se">\n</span><span class="s">'</span><span class="p">,</span> <span class="n">label_val</span><span class="p">.</span><span class="n">value_counts</span><span class="p">())</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n\n\n</span><span class="s">'</span><span class="p">)</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>
    <p>코드 : https://guru.tistory.com/35</p>
  </li>
  <li>
    <p>코드 : https://jinnyjinny.github.io/deep%20learning/2020/04/02/Kfold/</p>
  </li>
  <li>
    <p>이론 : https://steadiness-193.tistory.com/287</p>
  </li>
</ul>

<h1 id="5-코드-분석">5. 코드 분석</h1>

<ul>
  <li>OpenAI CLIP</li>
</ul>

<p><img src="../images/pages/CLIP.png" alt="CLIP.png" /></p>

<p>CLIP(Contrastive Language-Image Pre-Training)은 다양한 (이미지, 텍스트) 쌍으로 훈련된 신경망입니다. (이미지, 물체 분류) 데이터 대신 (이미지, 텍스트)의 데이터를 사용하는데, 수작업 labeling 없이 웹 크롤링을 통해 자동으로 이미지와 그에 연관된 자연어 텍스트를 추출하여 4억개의 (이미지-텍스트) 쌍을 가진 거대 데이터셋을 구축하였습니다.</p>

<p>작업에 대한 직접 최적화 없이 주어진 이미지에서 가장 관련성 높은 텍스트 스니펫을 예측하도록 할 수 있습니다. CLIP의 성능은 ResNet50정도로 뛰어난 편에 속합니다.</p>

<p>CLIP은 ImageNet의 대용량 데이터셋으로 미리 학습시킨 네트워크를 가져와 약간의 추가적인 학습만 수행하여도 원하는 task에서 훌륭한 성능을 낼 수 있어, 여러 분야에서 활발히 활용되고 있습니다.</p>

<p>CLIP 제작자 설명  : https://github.com/openai/CLIP</p>

<ul>
  <li>https://inforience.net/2021/02/09/clip_visual-model_pre_training/</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>train['path'] = train['Id'].map(lambda x: '../input/petfinder-pawpularity-score/train/'+x+'.jpg')
</code></pre></div></div>

<ul>
  <li>
    <p>train과 test 데이터에 path 컬럼 추가.</p>

    <p>path+id.jpg 값을 넣어줌.</p>
  </li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>if test.shape[0]&lt;10:
    test = pd.concat([
        test, test, test, test, test, 
    ])
    test = test.reset_index(drop=True)
</code></pre></div></div>

<ul>
  <li>
    <p>기존 test 데이터의 수를 늘려줌.</p>

    <p>if 블록의 역할은 기존의 test데이터 수를 늘려주는 것입니다.
8 + 8 + 8 + 8 + 8로, 그대로 test데이터를 연장시켜주었습니다.
(근데 같은 데이터값이고 index colum만 달라지는데 굳이..? 왜..?)</p>
  </li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>train['bins'] = (train['Pawpularity']//5).round()

train['fold0'] = -1
skf = StratifiedKFold(n_splits = 20, shuffle=True, random_state = 1)
for i, (_, test_index) in enumerate(skf.split(train.index, train['bins'])):
    train.iloc[test_index, -1] = i

train['fold0'] = train['fold0'].astype('int')
gc.collect()

train.groupby(['fold0'])['Pawpularity'].agg(['mean','std','count'])
</code></pre></div></div>

<ul>
  <li>
    <p>bins 열</p>

    <p>stratified K fold 라벨을 20개로 맞춰주기도 하고, stratified K fold에서 pawpularity의 라벨링 비율을 맞춰주기 위해 사용 (1-100 까지의 정답라벨 존재, //5 하면 20개로 나뉘어짐)</p>
  </li>
  <li>StratifiedKFold
    <ul>
      <li>불균형한 dataset일 경우 사용하는 kfold 방법</li>
      <li>k개의 fold를 분할한 이후에도 전체 훈련 데이터의 class 비율과 각 fold가 가지고 있는 class 비율을 맞춰줍니다.</li>
    </ul>
  </li>
  <li>
    <p>enumerate문</p>

    <p>나도 모르겠음.</p>
  </li>
  <li>
    <p>astype</p>

    <p>train[‘fold0’] 컬럼을 int형으로 변환</p>
  </li>
  <li>
    <p>groupby</p>

    <p><code class="language-plaintext highlighter-rouge">train.groupby(['fold0'])['Pawpularity'].agg(['mean','std','count'])</code></p>

    <p>fold마다 pawpularity의 mean(평균), std(표준편차), count(개수)값을 나타내줍니다.</p>

    <p>fold마다 제대로 stratified k fold 잘 되었는지 확인하기 위해 쓴듯</p>

    <p><img src="D:%5CGithub%5CtistoryPostings%5Cartificial%20Intelligence%5Cimages%5Cpages%5Cimage-20220209202030083.png" alt="image-20220209202030083" /></p>
  </li>
</ul>

<h2 id="timm-library">timm library</h2>

<p>PyTorch Image Models(timm)는 이미지 모델, 레이어, 유틸리티, 옵티마이저, 스케줄러, 데이터 로더/증강 및 참조 교육/검증 스크립트의 모음으로, ImageNet 교육 결과를 재현할 수 있는 다양한 SOTA 모델을 통합하는 것을 목표로 합니다.</p>

<p><img src="../images/pages/image-20220209011128949.png" alt="image-20220209011128949" /></p>

<p>https://github.com/rwightman/pytorch-image-models#introduction</p>

<blockquote>
  <p>보다시피 timm 라이브러리에서 사용할 수 있는 사전 훈련된 모델 아키텍처가 575개 있습니다.¶</p>

  <p>솔루션의 첫 번째 부분은 기본적으로 해당 모델의 마지막 계층에서 특징을 추출하고 추출된 특징에 대해 SVR을 실행하는 것입니다</p>

  <p>timm의 모델들은 대부분 Imagenet에서 1000개의 클래스를 사용하여 훈련되기 때문에 출력 모양은 모델마다 1000개입니다.
모든 575 모델에서 기능을 추출하는 것은 특히 제출 시간이 9시간이라는 점을 고려할 때 말도 안되고 상상도 할 수 없는 일이다. 따라서 RMSE 측면에서 성능이 좋은 모델의 하위 집합을 찾아보았습니다.</p>

  <p>이를 위해 RMSE 힐 클라이밍 알고리즘에 따라 전진 모델 선택 알고리즘을 사용했다. 한 모델부터 시작하여 RMSE 성능 향상을 중지할 때까지 모델을 계속 추가합니다.</p>

  <p>이제 Imagenet 사전 훈련된 모델 기능 추출을 시작하겠습니다.
이 솔루션에 사용된 전진 모델 선택 알고리즘에 의해 발견된 사전 교육된 모델은 위에 나열되어 있습니다.</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">modelpath</span> <span class="o">=</span> <span class="p">{</span> <span class="n">m</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">'/'</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">split</span><span class="p">(</span><span class="s">'.'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="p">:</span><span class="n">m</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">glob</span><span class="p">(</span><span class="s">'../input/pytorch-pretrained-0/*.pt'</span><span class="p">)</span><span class="o">+</span><span class="n">glob</span><span class="p">(</span><span class="s">'../input/pytorch-pretrained-1/*.pt'</span><span class="p">)</span><span class="o">+</span><span class="n">glob</span><span class="p">(</span><span class="s">'../input/pytorch-pretrained-2/*.pt'</span><span class="p">)</span><span class="o">+</span><span class="n">glob</span><span class="p">(</span><span class="s">'../input/pytorch-pretrained-3/*.pt'</span><span class="p">)}</span>
<span class="n">modelpath</span>
</code></pre></div></div>

<p>str = ../input/pytorch-pretrained-0/resnetv2_101x1_bitm.pt 일때,</p>

<p>str.split(‘/’) 의 결과</p>

<blockquote>
  <p>[’..’, ‘input’, ‘pytorch-pretrained-0’, ‘resnetv2_101x1_bitm.pt’]</p>
</blockquote>

<p>str.split(‘/’)[-1] 의 결과</p>

<blockquote>
  <p>‘resnetv2_101x1_bitm.pt’</p>
</blockquote>

<p>str.split(‘/’)[-1].split(‘.’)의 결과</p>

<blockquote>
  <p>[‘resnetv2_101x1_bitm’, ‘pt’]</p>
</blockquote>

<p>&lt; 참고 &gt;</p>

<p><img src="../images/pages/image-20220209011713971.png" alt="image-20220209011713971" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># EMB TEST가 뭘까
</span><span class="n">EMB_TEST</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">arch</span> <span class="ow">in</span> <span class="n">names</span><span class="p">:</span>
    <span class="n">starttime</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">timm</span><span class="p">.</span><span class="n">create_model</span><span class="p">(</span><span class="n">arch</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="s">'cuda'</span><span class="p">)</span>
    <span class="n">model</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">modelpath</span><span class="p">[</span><span class="n">arch</span><span class="p">]))</span>
    <span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>

    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">PawpularDataset</span><span class="p">(</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">test</span><span class="p">.</span><span class="n">Id</span><span class="p">.</span><span class="n">values</span><span class="p">,</span>
        <span class="n">base_path</span><span class="o">=</span><span class="s">'../input/petfinder-pawpularity-score/test/'</span><span class="p">,</span>
        <span class="n">modelcfg</span> <span class="o">=</span> <span class="n">resolve_data_config</span><span class="p">({},</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">),</span>
        <span class="n">aug</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">BS</span> <span class="o">=</span> <span class="mi">10</span> <span class="k">if</span> <span class="n">arch</span> <span class="ow">in</span> <span class="p">[</span><span class="s">'tf_efficientnet_l2_ns'</span><span class="p">]</span> <span class="k">else</span> <span class="mi">16</span>
    <span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">res</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="p">(</span><span class="n">img</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="s">'cuda'</span><span class="p">)).</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">train_dataloader</span><span class="p">]</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">EMB_TEST</span><span class="p">[</span><span class="n">arch</span><span class="p">]</span> <span class="o">=</span> <span class="n">res</span>
    
    <span class="k">print</span><span class="p">(</span> <span class="n">arch</span><span class="p">,</span> <span class="s">', Done in:'</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">starttime</span><span class="p">),</span> <span class="s">'s'</span> <span class="p">)</span>
    
    <span class="k">del</span> <span class="n">model</span><span class="p">,</span> <span class="n">res</span>
    <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">empty_cache</span><span class="p">()</span> <span class="c1"># PyTorch thing to clean RAM
</span>    <span class="n">gc</span><span class="p">.</span><span class="n">collect</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="p">)</span>    
<span class="nb">len</span><span class="p">(</span><span class="n">EMB_TEST</span><span class="p">),</span> <span class="n">EMB_TEST</span><span class="p">.</span><span class="n">keys</span><span class="p">()</span>
</code></pre></div></div>

<ul>
  <li>timm.create_model(arch, pretrained=False).to(‘cuda’)
    <ul>
      <li>
        <p>timm.create_model</p>

        <blockquote>
          <p><code class="language-plaintext highlighter-rouge">timm</code> is a deep-learning library created by <a href="https://twitter.com/wightmanr">Ross Wightman</a> and is a collection of SOTA computer vision models, layers, utilities, optimizers, schedulers, data-loaders, augmentations and also training/validating scripts with ability to reproduce ImageNet training results.</p>
        </blockquote>

        <p>https://fastai.github.io/timmdocs/</p>

        <p>pretrained=false인 상태로 names의 객체들을 불러와 모델을 생성해줍니다. gpu를 사용할 수 있도록 <code class="language-plaintext highlighter-rouge">.to('cuda')</code>명령어를 사용해 주었습니다.</p>

        <p>그밖의 gpu를 사용할 수있는 명령어는 다음과 같습니다.</p>

        <ul>
          <li>
            <p>x = torch.tensor([1., 2.], device=”cuda”)</p>
          </li>
          <li>
            <p>x = torch.tensor([1., 2.]).cuda()</p>
          </li>
          <li>
            <p>https://y-rok.github.io/pytorch/2020/10/03/pytorch-gpu.html</p>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>load_state_dict(torch.load(modelpath[arch]))
    <ul>
      <li>load_state_dict는 가중치를 불러오는 메소드입니다.</li>
      <li>
        <p>새로운 모델 인스턴스를 생성한 후에 가중치를 불러올 경우, pretrained =False를 주고, load_state_dict메소드를 이용해 가중치 값을불러오게 됩니다.</p>
      </li>
      <li>https://tutorials.pytorch.kr/beginner/basics/saveloadrun_tutorial.html</li>
    </ul>
  </li>
  <li>model.eval()
    <ul>
      <li>
        <p>추론(inference)을 하기 전에 <code class="language-plaintext highlighter-rouge">model.eval()</code> 메소드를 호출하여 드롭아웃(dropout)과 배치 정규화(batch normalization)를 평가 모드(evaluation mode)로 설정해야 합니다. 그렇지 않으면 일관성 없는 추론 결과가 생성됩니다.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">.eval()</code> 함수는 evaluation 과정에서 사용하지 않아야 하는 layer들을 알아서 off 시키도록 하는 함수이며</p>

        <p>evaluation/validation 과정에선 보통 <code class="language-plaintext highlighter-rouge">model.eval()</code>과 <code class="language-plaintext highlighter-rouge">torch.no_grad()</code>를 함께 사용합니다.</p>
      </li>
      <li>
        <p>사용 방법 관련 url : https://tutorials.pytorch.kr/beginner/basics/saveloadrun_tutorial.html</p>
      </li>
      <li>
        <p>eval 이 무엇인지 : https://stackoverflow.com/questions/60018578/what-does-model-eval-do-in-pytorch/60018731#60018731</p>
      </li>
      <li>
        <p>eval 이 무엇인지 : https://bluehorn07.github.io/2021/02/27/model-eval-and-train.html</p>
      </li>
    </ul>
  </li>
  <li>DataLoader(train_dataset, batch_size=BS, num_workers= 2, shuffle=False)
    <ul>
      <li>
        <p>dataloader는 기본적으로 단일 프로세스 데이터 로드를 사용합니다. num_workers 에 양의 정수를 설정하게되면, 지정된 수의 로더 작업자 프로세스로 멀티 프로세스 데이터 로드가 켜집니다.</p>
      </li>
      <li>
        <p>https://tutorials.pytorch.kr/beginner/basics/data_tutorial.html</p>
      </li>
    </ul>
  </li>
  <li>with torch.no_grad():
    <ul>
      <li>자원을 획득하고 사용 후 반납해야 하는 경우에 주로 사용합니다.</li>
      <li>프로세스 : 현재 실행되고 있는 프로그램
        <ul>
          <li>자원 : 기억장치 Ram이나 프로세서 디스크 등의 하드웨어 장치나 메시지, 파일등의 소프트웨어 요소들</li>
        </ul>
      </li>
      <li>https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&amp;blogId=wideeyed&amp;logNo=221653260516</li>
    </ul>
  </li>
</ul>

<p>Now its time to fit a GPU accelerated SVR using cuml<a href="https://www.kaggle.com/titericz/imagenet-embeddings-rapids-svr-finetuned-models/notebook#Now-its-time-to-fit-a-GPU-accelerated-SVR-using-cuml">¶</a></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">kfoldcol</span><span class="p">].</span><span class="nb">max</span><span class="p">()</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">ind_train</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">kfoldcol</span><span class="p">]</span> <span class="o">!=</span> <span class="n">fold</span>
        <span class="n">ind_valid</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">kfoldcol</span><span class="p">]</span> <span class="o">==</span> <span class="n">fold</span>

</code></pre></div></div>

<ul>
  <li>이해못함 ^_^/</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">SVR</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mf">16.0</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s">'rbf'</span><span class="p">,</span> <span class="n">degree</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">4000</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="s">'numpy'</span><span class="p">)</span>
        <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">TRAIN</span><span class="p">[</span><span class="n">ind_train</span><span class="p">],</span> <span class="n">train</span><span class="p">.</span><span class="n">Pawpularity</span><span class="p">[</span><span class="n">ind_train</span><span class="p">].</span><span class="n">clip</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">85</span><span class="p">)</span>  <span class="p">)</span>

        <span class="n">ypredtrain_</span><span class="p">[</span><span class="n">ind_valid</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">clip</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">TRAIN</span><span class="p">[</span><span class="n">ind_valid</span><span class="p">]),</span> <span class="mi">1</span> <span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
        <span class="n">ypredtest_</span> <span class="o">+=</span> <span class="n">np</span><span class="p">.</span><span class="n">clip</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">TEST</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li>
    <p>SVR</p>

    <p>Rapids SVR을 사용하는 방법은 쉽네요. cuml.svm 패키지에서 SVR을 import 해서 사용해주었습니다.</p>
  </li>
  <li>
    <p>np.clip(array, min, max)</p>

    <p>array내의 element에 대하여 min값보다 작은 값들을 min으로 바꿔주고, max보다 큰 값을 max로 만들어줍니다.</p>
  </li>
</ul>

<blockquote>
  <p>첫째, 각 아키텍처에 대해 하나의 SVR을 독립적으로 장착합니다.</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">names</span><span class="p">:</span>
    
    <span class="n">TRAIN</span> <span class="o">=</span> <span class="n">EMB_TRAIN</span><span class="p">[</span><span class="n">col</span><span class="p">].</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">TEST</span> <span class="o">=</span> <span class="n">EMB_TEST</span><span class="p">[</span><span class="n">col</span><span class="p">].</span><span class="n">copy</span><span class="p">()</span>

    <span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
    <span class="n">scaler</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span> <span class="n">np</span><span class="p">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">TRAIN</span><span class="p">,</span> <span class="n">TEST</span><span class="p">))</span> <span class="p">)</span>
    <span class="n">TRAIN</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">TRAIN</span><span class="p">)</span>
    <span class="n">TEST</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">TEST</span><span class="p">)</span>
    
    <span class="n">ypredtrain</span><span class="p">,</span> <span class="n">ypredtest</span> <span class="o">=</span> <span class="n">fit_gpu_svr</span><span class="p">(</span><span class="n">TRAIN</span><span class="p">,</span> <span class="n">TEST</span><span class="p">,</span> <span class="s">'fold0'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">rmse</span><span class="p">(</span><span class="n">train</span><span class="p">.</span><span class="n">Pawpularity</span><span class="p">,</span><span class="n">ypredtrain</span><span class="p">),</span> <span class="n">col</span><span class="p">)</span>    
</code></pre></div></div>

<ul>
  <li>
    <p>StandartScaler()</p>

    <p><img src="D:%5CGithub%5CtistoryPostings%5Cartificial%20Intelligence%5Cimages%5Cpages%5Cimage-20220209213749442.png" alt="image-20220209213749442" style="zoom: 67%;" /> -&gt;<img src="D:%5CGithub%5CtistoryPostings%5Cartificial%20Intelligence%5Cimages%5Cpages%5Cimage-20220209213757080.png" alt="image-20220209213757080" /></p>

    <ul>
      <li>
        <p>평균 0 , 분산 1로 조정합니다</p>
      </li>
      <li>
        <p>보통의 싸이킷런 함수들과 비슷하게 fit, transform, fit_transform 다 지원합니다.</p>
      </li>
      <li>
        <p>https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&amp;blogId=demian7607&amp;logNo=222009975984</p>
      </li>
    </ul>
  </li>
  <li>np.vstack
    <ul>
      <li>두 배열을 위에서 아래로 붙이기</li>
      <li><img src="D:%5CGithub%5CtistoryPostings%5Cartificial%20Intelligence%5Cimages%5Cpages%5Cimage-20220211200744146.png" alt="image-20220211200744146" /></li>
      <li>np.hstack
        <ul>
          <li>두 배열을 왼쪽에서 오른쪽으로 붙이기</li>
        </ul>
      </li>
      <li>https://rfriend.tistory.com/352</li>
    </ul>
  </li>
  <li>StandardScaler.transform()
    <ul>
      <li>정규화 / 표준화 Standardization, z = (𝑥-𝜇)/𝜎</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>위에서 볼 수 있듯이, 개별 아키텍처에서 추출된 기능의 SVR RMSE 범위는 17.56 ~ 18.52입니다.</p>

  <p>하지만 SVR에 맞추기 전에 아키텍처 기능을 나란히 쌓으면 어떻게 될까요?</p>

  <p>일부 기능 연결 및 표준화</p>

  <p>모든 K 폴드를 사용하여 SVR A를 장착합니다.
RMSE를 약간 증가시킨 85에서 목표물을 클립하는 것을 발견했어요.</p>
</blockquote>

<blockquote>
  <p>또한 1.032의 승수를 사용하면 CV와 LB가 모두 향상된다는 것을 알게 되었습니다. 이는 SRV가 RMSE가 아닌 평균 제곱 오차를 최적화하기 때문일 수 있다.</p>
</blockquote>

<blockquote>
  <p>이제 두 번째 feature 부분 집합을 사용하여 SVR B를 장착합니다. 더 많은 하위 집합을 적합시키는 아이디어는 후방 모델 앙상블에 다양성을 추가하고 형상 수를 너무 많이 증가시키는 차원성의 저주를 피하기 위한 것이다.</p>
</blockquote>

<blockquote>
  <p>이제 딥 러닝 미세 조정된 이미지 모델을 사용하여 추론을 실행합니다.</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="nn">albumentations</span> <span class="k">as</span> <span class="n">A</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">'cuda'</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">Config</span><span class="p">:</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="s">"swin_large_patch4_window7_224"</span>
    <span class="n">base_dir</span> <span class="o">=</span> <span class="s">"../input/petfinder-pawpularity-score"</span>
    <span class="n">data_dir</span> <span class="o">=</span> <span class="n">base_dir</span>
    <span class="n">model_dir</span> <span class="o">=</span> <span class="s">"exp"</span>
    <span class="n">output_dir</span> <span class="o">=</span> <span class="n">model_dir</span>
    <span class="n">img_test_dir</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s">"test"</span><span class="p">)</span>
    <span class="n">model_path</span> <span class="o">=</span> <span class="s">"swin_large_patch4_window7_224"</span>
    <span class="n">im_size</span> <span class="o">=</span>  <span class="mi">384</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>


<span class="k">class</span> <span class="nc">PetDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_filepaths</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">image_filepaths</span> <span class="o">=</span> <span class="n">image_filepaths</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>
    
    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">image_filepaths</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="n">image_filepath</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">image_filepaths</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">image_filepath</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nb">open</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
            <span class="n">image_rgb</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">convert</span><span class="p">(</span><span class="s">'RGB'</span><span class="p">)</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">image_rgb</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="p">)[</span><span class="s">"image"</span><span class="p">]</span>
        
        <span class="n">image</span> <span class="o">=</span> <span class="n">image</span> <span class="o">/</span> <span class="mi">255</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)).</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">target</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">targets</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

        <span class="n">image</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">image</span><span class="p">,</span> <span class="n">target</span>    


<span class="k">def</span> <span class="nf">get_inference_fixed_transforms</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">224</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># do not original aspects, colors and angles
</span>        <span class="k">return</span> <span class="n">A</span><span class="p">.</span><span class="n">Compose</span><span class="p">([</span>
                <span class="n">A</span><span class="p">.</span><span class="n">SmallestMaxSize</span><span class="p">(</span><span class="n">max_size</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">),</span>
                <span class="n">A</span><span class="p">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="n">height</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">),</span>
            <span class="p">],</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">A</span><span class="p">.</span><span class="n">Compose</span><span class="p">([</span>
                <span class="n">A</span><span class="p">.</span><span class="n">SmallestMaxSize</span><span class="p">(</span><span class="n">max_size</span><span class="o">=</span><span class="n">dim</span><span class="o">+</span><span class="mi">16</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">),</span>
                <span class="n">A</span><span class="p">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="n">height</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">),</span>
                <span class="n">A</span><span class="p">.</span><span class="n">HorizontalFlip</span><span class="p">(</span><span class="n">p</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">)</span>
            <span class="p">],</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">PetNet</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_name</span> <span class="o">=</span> <span class="n">Config</span><span class="p">.</span><span class="n">model_path</span><span class="p">,</span>
        <span class="n">out_features</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">inp_channels</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">pretrained</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">timm</span><span class="p">.</span><span class="n">create_model</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">in_chans</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>    


<span class="k">def</span> <span class="nf">tta_fn</span><span class="p">(</span><span class="n">filepaths</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">ttas</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Image Size:'</span><span class="p">,</span> <span class="n">Config</span><span class="p">.</span><span class="n">im_size</span><span class="p">)</span>
    <span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
    <span class="n">tta_preds</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">tta_mode</span> <span class="ow">in</span> <span class="n">ttas</span><span class="p">:</span><span class="c1">#range(Config.tta_times):
</span>        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'tta mode:</span><span class="si">{</span><span class="n">tta_mode</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
        <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">PetDataset</span><span class="p">(</span>
          <span class="n">image_filepaths</span> <span class="o">=</span> <span class="n">filepaths</span><span class="p">,</span>
          <span class="n">targets</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">filepaths</span><span class="p">)),</span>
          <span class="n">transform</span> <span class="o">=</span> <span class="n">get_inference_fixed_transforms</span><span class="p">(</span><span class="n">tta_mode</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="n">Config</span><span class="p">.</span><span class="n">im_size</span> <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
          <span class="n">test_dataset</span><span class="p">,</span>
          <span class="n">batch_size</span> <span class="o">=</span> <span class="n">Config</span><span class="p">.</span><span class="n">batch_size</span><span class="p">,</span>
          <span class="n">shuffle</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
          <span class="n">num_workers</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
          <span class="n">pin_memory</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="p">)</span>
        <span class="c1">#stream = tqdm(test_loader)
</span>        <span class="n">tta_pred</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span><span class="c1">#enumerate(stream, start = 1):
</span>            <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span> <span class="o">=</span> <span class="bp">True</span><span class="p">).</span><span class="nb">float</span><span class="p">()</span>
            <span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span> <span class="o">=</span> <span class="bp">True</span><span class="p">).</span><span class="nb">float</span><span class="p">().</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

            <span class="n">pred</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">output</span><span class="p">).</span><span class="n">detach</span><span class="p">().</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span> <span class="o">*</span> <span class="mi">100</span><span class="p">).</span><span class="n">ravel</span><span class="p">().</span><span class="n">tolist</span><span class="p">()</span>
            <span class="n">tta_pred</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
        <span class="n">tta_preds</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">tta_pred</span><span class="p">))</span>
    
    <span class="n">fold_preds</span> <span class="o">=</span> <span class="n">tta_preds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tta_preds</span><span class="p">)):</span>
        <span class="n">fold_preds</span> <span class="o">+=</span> <span class="n">tta_preds</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>
    <span class="n">fold_preds</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tta_preds</span><span class="p">)</span>
        
    <span class="k">del</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">test_dataset</span>
    <span class="n">gc</span><span class="p">.</span><span class="n">collect</span><span class="p">()</span>
    <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">empty_cache</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">fold_preds</span>    
</code></pre></div></div>

<blockquote>
  <p>cuML SVR A, B, C 및 이미지 모델 앙상블의 OOF 예측을 사용하여 전체 RMSE를 최적화합니다.</p>
</blockquote>

<h2 id="oof-out-of-fold">OOF out of fold</h2>

<ul>
  <li>
    <p>머신러닝 모델의 성능을 평가하는 방법</p>
  </li>
  <li>
    <p>OOF 방식은 실무보다는 Kaggle, Dacon과 같은 예측 알고리즘 대회에서 자주 사용되는 방식이며 fold를 사용</p>
  </li>
  <li>
    <p>두가지 방식</p>

    <ul>
      <li>Stacking
        <ul>
          <li>5 Fold 기반으로 개별 모델이 5회 번갈아 가면 4/5 학습 데이터로 학습하고, 1/5 학습 데이터로 예측하여 별도의 학습 데이터를 만듭니다. 그리고 이렇게 만들어진 학습 데이터를 다시 메타 모델이(아마도 Model 6) 학습하여 최종 예측 하는 방식입니다.</li>
        </ul>
      </li>
      <li>개별 예측값 평균하는 방법
        <ul>
          <li>K-Fold로 학습을 수행 한 뒤 예측을 테스트 데이터에 K번 만큼 수행한 뒤 개별 예측값을 평균하여 최종 예측</li>
          <li><img src="D:%5CGithub%5CtistoryPostings%5Cartificial%20Intelligence%5Cimages%5Cpages%5Cimg.png" alt="img" /></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>https://techblog-history-younghunjo1.tistory.com/142</p>
  </li>
  <li>
    <p>위 그림의 좌측은 4개의 Fold로 교차검증하는 K=4 일때의 K-fold 교차검증 방법이다. 이렇게 총 4번의 교차검증으로 (동일한 하이퍼파라미터를 사용한) 예측 알고리즘으로 각 검증 데이터로 평가한 Model 1~4를 만들어낸다.(이 때, Model 1,2,3,4에서 각각 최적화된 파라미터 값들은 다를 것이다. 왜냐하면 각 모델이 학습한 데이터가 서로 다르기 때문이다.)</p>
  </li>
  <li>
    <p>그리고 난 후, <strong>Model 1~4를 동일한 테스트 데이터에 대해 예측</strong>하도록 하여 각 Model 별 테스트 데이터에 대한 예측값을 계산한다. 이렇게 되면 위 그림에서 노란색 박스의 Model 1~4 예측값이 나오게 된다.</p>

    <p>마지막으로 할 일은 <strong>이 4개의 예측값들의 평균값을 취하여 테스트 데이터에 대한 최종 예측값을 계산</strong>한다.</p>
  </li>
</ul>]]></content><author><name>Armando Maynez</name></author><summary type="html"><![CDATA[오늘은 새로 가입한 kaggle 스터디에서 발표준비를 하면서 공부한 내용을 정리해 보았습니다.]]></summary></entry><entry><title type="html">[kaggle 참가하고 싶은 대회 리스트</title><link href="http://localhost:4000/kaggle-%EC%B0%B8%EA%B0%80%ED%95%98%EA%B3%A0-%EC%8B%B6%EC%9D%80-%EB%8C%80%ED%9A%8C-%EB%A6%AC%EC%8A%A4%ED%8A%B8.html" rel="alternate" type="text/html" title="[kaggle 참가하고 싶은 대회 리스트" /><published>2022-02-08T00:00:00+09:00</published><updated>2022-02-08T00:00:00+09:00</updated><id>http://localhost:4000/%5Bkaggle%20%EC%B0%B8%EA%B0%80%ED%95%98%EA%B3%A0%20%EC%8B%B6%EC%9D%80%20%EB%8C%80%ED%9A%8C%20%EB%A6%AC%EC%8A%A4%ED%8A%B8</id><content type="html" xml:base="http://localhost:4000/kaggle-%EC%B0%B8%EA%B0%80%ED%95%98%EA%B3%A0-%EC%8B%B6%EC%9D%80-%EB%8C%80%ED%9A%8C-%EB%A6%AC%EC%8A%A4%ED%8A%B8.html"><![CDATA[<h1 id="1-im-something-of-a-painter-myself">1. I’m Something of a Painter Myself</h1>

<p>https://www.kaggle.com/c/gan-getting-started</p>

<p>GAN은 생성기 모델과 판별기 모델의 두 개 이상의 신경망으로 구성됩니다. 생성기는 이미지를 생성하는 신경망입니다. 경쟁을 위해 Monet 스타일로 이미지를 생성해야 합니다. 이 생성기는 판별자를 사용하여 학습됩니다.</p>

<p>생성자는 판별자를 속이려고 하고 판별자는 실제 대 생성된 이미지를 정확하게 분류하려고 하는 두 모델이 서로에 대해 작동합니다.</p>

<p>당신의 임무는 7,000~10,000개의 모네 스타일 이미지를 생성하는 GAN을 만드는 것입니다.</p>

<h1 id="2-petfindermy---pawpularity-contest">2. PetFinder.my - Pawpularity Contest</h1>

<p>https://www.kaggle.com/c/petfinder-pawpularity-score</p>

<p><a href="https://petfinder.my/">PetFinder.my</a> 는 180,000마리 이상의 동물과 54,000마리가 행복하게 입양된 말레이시아 최고의 동물 복지 플랫폼입니다. PetFinder는 동물 애호가, 미디어, 기업 및 글로벌 조직과 긴밀하게 협력하여 동물 복지를 개선합니다.</p>

<p>현재 PetFinder.my는 기본 <a href="https://petfinder.my/cutenessmeter">귀여움 측정기</a> 를 사용하여 애완 동물 사진의 순위를 매깁니다. 수천 개의 애완 동물 프로필의 성능과 비교하여 사진 구성 및 기타 요소를 분석합니다. 이 기본 도구는 유용하지만 아직 실험 단계에 있으며 알고리즘을 개선할 수 있습니다.</p>

<h1 id="3-lyft-motion-prediction-for-autonomous-vehicles">3. Lyft Motion Prediction for Autonomous Vehicles</h1>

<p>https://www.kaggle.com/c/lyft-motion-prediction-autonomous-vehicles</p>

<p>이 대회에서는 데이터 과학 기술을 적용하여 자율 주행 차량용 모션 예측 모델을 구축합니다. 모델을 훈련하고 테스트하기 위해 출시된 가장 큰 <a href="https://self-driving.lyft.com/level5/prediction/">예측 데이터 세트</a> 에 액세스할 수 있습니다 . 그런 다음 자동 학습 환경에서 자동차, 자전거 타는 사람 및 보행자가 움직이는 방식을 예측하려면 기계 학습에 대한 지식이 필요합니다.</p>

<h1 id="4-natural-language-processing-with-disaster-tweets">4. Natural Language Processing with Disaster Tweets</h1>

<p>https://www.kaggle.com/c/nlp-getting-started</p>

<p>트위터는 비상시에 중요한 커뮤니케이션 채널이 되었습니다.
스마트폰의 보편화로 인해 사람들은 실시간으로 관찰 중인 긴급 상황을 알릴 수 있습니다. 이 때문에 더 많은 기관이 Twitter를 프로그래밍 방식으로 모니터링하는 데 관심이 있습니다(예: 재난 구호 단체 및 뉴스 기관).</p>

<p>그러나 사람의 말이 실제로 재난을 알리는 것인지 항상 명확하지 않습니다. 다음 예를 들어보세요.</p>

<p>이 대회에서는 실제 재해에 대한 트윗과 그렇지 않은 트윗을 예측하는 기계 학습 모델을 구축해야 합니다. 손으로 분류한 10,000개의 트윗 데이터 세트에 액세스할 수 있습니다. NLP 문제에 대한 작업이 처음인 경우 시작하고 실행할 수 있도록 <a href="https://www.kaggle.com/philculliton/nlp-getting-started-tutorial">빠른 자습서 를 만들었습니다.</a></p>

<p>면책 조항: 이 대회의 데이터 세트에는 모독적이거나 저속하거나 공격적인 것으로 간주될 수 있는 텍스트가 포함되어 있습니다.</p>

<h1 id="5-lux-ai">5. Lux AI</h1>

<p>https://www.kaggle.com/c/lux-ai-2021/overview/description</p>

<p>밤은 어둡고 공포로 가득 차 있습니다. 두 팀은 어둠과 싸워야 하고, 자원을 수집하고, 시대를 초월해 전진해야 합니다. 낮에는 도시를 성장시키면서 임박한 밤을 보낼 수 있는 자원을 모으기 위해 필사적으로 서두르게 됩니다. 신중하게 계획하고 확장하십시오. 충분한 빛을 생산하지 못하는 도시는 어둠에 휩싸일 것입니다.</p>

<h1 id="6-shopee---price-match-guarantee">6. Shopee - Price Match Guarantee</h1>

<p>https://www.kaggle.com/c/shopee-product-matching</p>

<p>유사한 상품의 두 가지 다른 이미지는 동일한 제품 또는 완전히 다른 두 개의 항목을 나타낼 수 있습니다. 소매업체는 서로 다른 두 제품을 혼합하여 발생할 수 있는 허위 진술 및 기타 문제를 방지하기를 원합니다. 현재 딥 러닝과 기존 머신 러닝을 결합하여 이미지와 텍스트 정보를 분석하여 유사성을 비교합니다. 그러나 이미지, 제목 및 제품 설명의 주요 차이점으로 인해 이러한 방법이 완전히 효과적이지 않습니다.</p>

<p>Shopee는 동남아시아와 대만의 선도적인 전자 상거래 플랫폼입니다. 고객은 해당 지역에 맞는 쉽고 안전하며 빠른 온라인 쇼핑 경험을 높이 평가합니다. 이 회사는 또한 수천 개의 Shopee 목록에 있는 제품에 대한 ‘최저가 보장’ 기능과 함께 강력한 지불 및 물류 지원을 제공합니다.</p>

<p>이 대회에서는 기계 학습 기술을 적용하여 동일한 제품인 항목을 예측하는 모델을 구축합니다.</p>

<h1 id="7-peking-universitybaidu---autonomous-driving">7. Peking University/Baidu - Autonomous Driving</h1>

<p>https://www.kaggle.com/c/pku-autonomous-driving</p>

<p>Baidu의 Robotics and Autonomous Driving Lab(RAL)은 Peking University와 함께 이 도전을 통해 격차를 완전히 좁힐 수 있기를 희망합니다. 그들은 Kaggler에게 산업 등급 CAD 자동차 모델을 기반으로 하는 5,277개의 실제 이미지에서 60,000개 이상의 레이블이 지정된 3D 자동차 인스턴스를 제공하고 있습니다.</p>

<p>과제: 실제 교통 환경에서 단일 이미지에서 차량의 절대 자세(6자유도)를 추정하는 알고리즘을 개발하십시오.</p>

<p>성공하면 컴퓨터 비전을 개선하는 데 도움이 됩니다. 이는 차례로 자율주행차가 널리 채택되는 데 한 걸음 더 다가가게 하여 성장하는 사회의 환경적 영향을 줄이는 데 도움이 될 것입니다.</p>

<h1 id="8-talkingdata-adtracking-fraud-detection-challenge">8. TalkingData AdTracking Fraud Detection Challenge</h1>

<p>https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection</p>

<p>사기 위험은 어디에나 있지만 온라인 광고를 하는 회사의 경우 클릭 사기가 압도적으로 발생하여 잘못된 클릭 데이터와 비용 낭비를 초래할 수 있습니다. 광고 채널은 단순히 광고를 대규모로 클릭함으로써 비용을 증가시킬 수 있습니다. 매달 10억 개 이상의 스마트 모바일 장치가 사용되는 중국은
세계에서 가장 큰 모바일 시장이므로 엄청난 양의 사기 트래픽으로 고통받고 있습니다.</p>

<p><a href="https://www.talkingdata.com/">중국 최대의 독립 빅데이터 서비스 플랫폼인 TalkingData</a> 는 전국 활성 모바일 기기의 70% 이상을 커버합니다. 그들은 하루에 30억 번의 클릭을 처리하며 그 중 90%는 잠재적인 사기입니다. 앱 개발자를 위한 클릭 사기를 방지하기 위한 현재의 접근 방식은 포트폴리오 전체에서 사용자 클릭의 여정을 측정하고 많은 클릭을 생성하지만 앱을 설치하지 않는 IP 주소에 플래그를 지정하는 것입니다. 이 정보를 바탕으로 IP 블랙리스트와 기기 블랙리스트를 구축했습니다.</p>]]></content><author><name>Armando Maynez</name></author><summary type="html"><![CDATA[1. I’m Something of a Painter Myself]]></summary></entry><entry><title type="html">Kaggle ) imagenet embeddings+rapids svr+finetuned models 분석</title><link href="http://localhost:4000/Kaggle-)-Imagenet-embeddings+RAPIDS-SVR+Finetuned-models-%EB%B6%84%EC%84%9D.html" rel="alternate" type="text/html" title="Kaggle ) imagenet embeddings+rapids svr+finetuned models 분석" /><published>2022-02-08T00:00:00+09:00</published><updated>2022-02-08T00:00:00+09:00</updated><id>http://localhost:4000/Kaggle%20)%20Imagenet%20embeddings+RAPIDS%20SVR+Finetuned%20models%20%EB%B6%84%EC%84%9D</id><content type="html" xml:base="http://localhost:4000/Kaggle-)-Imagenet-embeddings+RAPIDS-SVR+Finetuned-models-%EB%B6%84%EC%84%9D.html"><![CDATA[<p>오늘은 새로 가입한 kaggle 스터디에서 발표준비를 하면서 공부한 내용을 정리해 보았습니다.</p>

<p>주제는 kaggle의 Pawpularity Contest이며,  링크는 다음과 같습니다.</p>

<ul>
  <li>kaggle의 주제 사이트</li>
</ul>

<ul>
  <li>분석할 코드 링크</li>
</ul>

<p>&lt; 목차 &gt;</p>

<h1 id="1-pawpularity-data">1. Pawpularity Data</h1>

<h2 id="sample_submissioncsv">sample_submission.csv</h2>

<p>[id, pawpularity] 로 구성</p>

<h2 id="testcsv">test.csv</h2>

<p>train에서 pawpularity가 없는 데이터입니다.</p>

<p>id값 빼고는 전부 0, 1 이진데이터입니다.</p>

<table>
  <thead>
    <tr>
      <th>id</th>
      <th>The photos unique Pet Profile ID corresponding to the photo’s file name.</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Subject Focus</td>
      <td>Pet stands out against uncluttered background, not too close / far.</td>
    </tr>
    <tr>
      <td>Eyes</td>
      <td>Both eyes are facing front or near-front, with at least 1 eye / pupil decently clear.</td>
    </tr>
    <tr>
      <td>Face</td>
      <td>Decently clear face, facing front or near-front.</td>
    </tr>
    <tr>
      <td>Near</td>
      <td>Single pet taking up significant portion of photo (roughly over 50% of photo width or height).</td>
    </tr>
    <tr>
      <td>Action</td>
      <td>Pet in the middle of an action (e.g., jumping).</td>
    </tr>
    <tr>
      <td>Accessory</td>
      <td>Accompanying physical or digital accessory / prop (i.e. toy, digital sticker), excluding collar and leash.</td>
    </tr>
    <tr>
      <td>Group</td>
      <td>More than 1 pet in the photo.</td>
    </tr>
    <tr>
      <td>Collage</td>
      <td>Digitally-retouched photo (i.e. with digital photo frame, combination of multiple photos).</td>
    </tr>
    <tr>
      <td>Human</td>
      <td>Human in the photo.</td>
    </tr>
    <tr>
      <td>Occlusion</td>
      <td>Specific undesirable objects blocking part of the pet (i.e. human, cage or fence). Note that not all blocking objects are</td>
    </tr>
    <tr>
      <td>Info</td>
      <td>Custom-added text or labels (i.e. pet name, description).</td>
    </tr>
    <tr>
      <td>Blur</td>
      <td>Noticeably out of focus or noisy, especially for the pet’s eyes and face. For Blur entries, “Eyes” column is always set to 0.</td>
    </tr>
  </tbody>
</table>

<h2 id="traincsv">train.csv</h2>

<p>id값, pawpularity 빼고는 전부 0, 1 이진데이터입니다.</p>

<p>pawpulairty는 1-100까지의 int형 data입니다.</p>

<table>
  <thead>
    <tr>
      <th>id</th>
      <th>The photos unique Pet Profile ID corresponding to the photo’s file name.</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Subject Focus</td>
      <td>Pet stands out against uncluttered background, not too close / far.</td>
    </tr>
    <tr>
      <td>Eyes</td>
      <td>Both eyes are facing front or near-front, with at least 1 eye / pupil decently clear.</td>
    </tr>
    <tr>
      <td>Face</td>
      <td>Decently clear face, facing front or near-front.</td>
    </tr>
    <tr>
      <td>Near</td>
      <td>Single pet taking up significant portion of photo (roughly over 50% of photo width or height).</td>
    </tr>
    <tr>
      <td>Action</td>
      <td>Pet in the middle of an action (e.g., jumping).</td>
    </tr>
    <tr>
      <td>Accessory</td>
      <td>Accompanying physical or digital accessory / prop (i.e. toy, digital sticker), excluding collar and leash.</td>
    </tr>
    <tr>
      <td>Group</td>
      <td>More than 1 pet in the photo.</td>
    </tr>
    <tr>
      <td>Collage</td>
      <td>Digitally-retouched photo (i.e. with digital photo frame, combination of multiple photos).</td>
    </tr>
    <tr>
      <td>Human</td>
      <td>Human in the photo.</td>
    </tr>
    <tr>
      <td>Occlusion</td>
      <td>Specific undesirable objects blocking part of the pet (i.e. human, cage or fence). Note that not all blocking objects are</td>
    </tr>
    <tr>
      <td>Info</td>
      <td>Custom-added text or labels (i.e. pet name, description).</td>
    </tr>
    <tr>
      <td>Blur</td>
      <td>Noticeably out of focus or noisy, especially for the pet’s eyes and face. For Blur entries, “Eyes” column is always set to 0.</td>
    </tr>
    <tr>
      <td>Pawpularity</td>
      <td>The Pawpularity Score is derived from each pet profile’s page view statistics at the listing pages, using an algorithm</td>
    </tr>
  </tbody>
</table>

<h1 id="2-openai-clip">2. OpenAI CLIP</h1>

<p>CLIP(Contrastive Language-Image Pre-Training)은 다양한 (이미지, 텍스트) 쌍으로 훈련된 신경망입니다. GPT-2 및 3의 제로샷 기능과 유사하게 작업에 대한 직접 최적화 없이 주어진 이미지에서 가장 관련성 높은 텍스트 스니펫을 예측하도록 자연어로 지시할 수 있습니다. 우리는 CLIP이 원본 ResNet50의 성능과 일치함을 발견했습니다. ImageNet에서 원래 128만 개의 레이블이 지정된 예제를 사용하지 않고 “제로샷”을 수행하여 컴퓨터 비전의 몇 가지 주요 문제를 극복했습니다.</p>

<p>참고 링크 : https://github.com/openai/CLIP</p>

<h1 id="image-embedding">Image Embedding</h1>

<h3 id="임베딩-embedding이란">임베딩 Embedding이란?</h3>

<p>고차원 벡터를 저차원 공간으로 변환하는 것입니다. 이상적으로, 임베딩은 임베딩 공간에서 의미적으로 비슷한 입력 사항들을 가깝게 배치함으로써 입력에 포함된 의미 중 일부를 포착합니다.</p>

<ul>
  <li>https://cloud.google.com/architecture/overview-extracting-and-serving-feature-embeddings-for-machine-learning?hl=ko</li>
</ul>

<h3 id="이미지-임베딩">이미지 임베딩</h3>

<p>텍스트 시스템과 달리, 이미지 처리 시스템은 개별적인 원시 픽셀 강도를 지닌 이미지를 나타내는 풍부하고 고차원적인 데이터세트로 작동합니다. 하지만 원래의 밀도가 높은 형태의 이미지는 일부 작업에 그리 유용하지 않을 수 있습니다. 예를 들어 잡지 표지 이미지를 보고 비슷한 잡지를 찾거나 참조 사진과 비슷한 사진을 찾아야 한다고 가정해보세요. 입력 사진의 원시 픽셀(2,048 ✕ 2,048)을 다른 사진과 비교하여 비슷한지 여부를 찾는 것은 효율적이거나 효과적이지 않습니다. 하지만 이미지의 저차원적 특성 벡터(임베딩)를 추출하면 이미지에 포함된 내용이 무엇인지를 나타내는 일정한 지표를 얻고, 더 효과적으로 비교할 수 있습니다.</p>

<p>핵심은 대규모 이미지 데이터 세트(예: <a href="https://arxiv.org/abs/1409.4842">ImageNet</a>)에서 <a href="https://arxiv.org/abs/1512.03385">Inception</a>, <a href="https://ai.googleblog.com/2017/11/automl-for-large-scale-image.html">ResNet(Deep Residual Learning)</a> 또는 <a href="http://image-net.org/">NASNet(Network Architecture Search)</a>과 같은 이미지 분류 모델을 학습시키는 것입니다. 그런 다음 마지막 <a href="https://wikipedia.org/wiki/Softmax_function">softmax</a> 분류 기준이 <em>없는</em> 모델을 사용하여 입력 테스트에 따라 특징 벡터를 추출합니다. 이 유형의 특징 벡터로 검색 작업 또는 유사성 일치 작업에서 이미지를 효과적으로 표현할 수 있습니다. 특징 벡터는 다른 특성과 함께 ML 작업용 추가 입력 특성(벡터)으로 작동할 수 있습니다. 예를 들어 의류를 쇼핑 중인 고객에게 패션 아이템을 추천하는 시스템에서는 색상, 치수, 가격, 유형, 하위유형을 비롯한 개별 항목을 기술하는 속성이 사용될 수 있습니다. 패션 아이템 이미지에서 추출된 특성과 함께 이러한 모든 특성을 추천 모델에서 사용할 수 있습니다.</p>

<h1 id="rapid-svr">RAPID SVR</h1>

<h1 id="stratifiedkfold">StratifiedKFold</h1>

<ul>
  <li>k-fold : 학습데이터셋과 검증 데이터 셋을 나누어서 진행하는 것</li>
  <li>startifiedkfold : 불균형한 dataset일 경우 사용하는 kfold 방법
    <ul>
      <li>k개의 fold를 분할한 이후에도 전체 훈련 데이터의 class 비율과 각 fold가 가지고 있는 class 비율을 맞춰줍니다.</li>
      <li><img src="../images/pages/img.png" alt="img" /></li>
    </ul>
  </li>
  <li>
    <p>코드 : https://guru.tistory.com/35</p>
  </li>
  <li>이론 : https://steadiness-193.tistory.com/287</li>
</ul>

<h1 id="코드-분석">코드 분석</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'../input/petfinderdata/train-folds-1.csv'</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'../input/petfinder-pawpularity-score/test.csv'</span><span class="p">)</span>
<span class="n">sub</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'../input/petfinder-pawpularity-score/sample_submission.csv'</span><span class="p">)</span>

<span class="n">train</span><span class="p">[</span><span class="s">'path'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'Id'</span><span class="p">].</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s">'../input/petfinder-pawpularity-score/train/'</span><span class="o">+</span><span class="n">x</span><span class="o">+</span><span class="s">'.jpg'</span><span class="p">)</span>
<span class="n">test</span><span class="p">[</span><span class="s">'path'</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="s">'Id'</span><span class="p">].</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s">'../input/petfinder-pawpularity-score/test/'</span><span class="o">+</span><span class="n">x</span><span class="o">+</span><span class="s">'.jpg'</span><span class="p">)</span>

<span class="c1">#print(test)
# If its Public LB run, then augment Testset to chack batch size memory consumption.
</span><span class="k">if</span> <span class="n">test</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">&lt;</span><span class="mi">10</span><span class="p">:</span>
    <span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span>
        <span class="n">test</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> 
    <span class="p">])</span>
    <span class="n">test</span> <span class="o">=</span> <span class="n">test</span><span class="p">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    
<span class="c1"># print(test)    
</span>
<span class="k">print</span><span class="p">(</span><span class="n">train</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">test</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">sub</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">train</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">50</span><span class="p">))</span>    

</code></pre></div></div>

<h2 id="train과-test-데이터에-path-컬럼-추가">train과 test 데이터에 path 컬럼 추가.</h2>

<p>path+id.jpg 값을 넣어줌.</p>

<h2 id="기존-test-데이터의-수를-늘려줌">기존 test 데이터의 수를 늘려줌.</h2>

<p>if 블록의 역할은 기존의 test데이터 수를 늘려주는 것입니다.
8 + 8 + 8 + 8 + 8로, 그대로 test데이터를 연장시켜주었습니다.
(근데 같은 데이터값이고 index colum만 달라지는데 굳이..? 왜..?)</p>

<h2 id="testreset_indexdrop--true"><code class="language-plaintext highlighter-rouge">test.reset_index(drop = True)</code></h2>

<p>drop매개변수를 사용하면 DataFrame에서 인덱스를 완전히 삭제할지 여부를 지정할 수 있습니다 . drop = True하면 reset_index가 인덱스를 DataFrame의 열에 다시 삽입하는 대신 삭제합니다. 를 설정 drop = True하면 현재 인덱스가 완전히 삭제되고 숫자 인덱스가 이를 대체합니다.</p>

<ul>
  <li>https://www.sharpsightlabs.com/blog/pandas-reset-index/</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># print(train.head(50))    
</span>
<span class="n">train</span><span class="p">[</span><span class="s">'bins'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'Pawpularity'</span><span class="p">]</span><span class="o">//</span><span class="mi">5</span><span class="p">).</span><span class="nb">round</span><span class="p">()</span>
<span class="c1"># print(train['Pawpularity'])
# print(train['Pawpularity'].value_counts())
# print(train.head(50))    
</span><span class="k">print</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'bins'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">())</span>



<span class="n">train</span><span class="p">[</span><span class="s">'fold0'</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="n">skf</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">skf</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">train</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">train</span><span class="p">[</span><span class="s">'bins'</span><span class="p">])):</span>
    <span class="n">train</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>

<span class="k">print</span><span class="p">(</span><span class="s">'test_index'</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span>    
<span class="k">print</span><span class="p">(</span><span class="s">'test_index len'</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_index</span><span class="p">))</span>
<span class="c1"># print(train.head(50))    
</span>    
<span class="n">train</span><span class="p">[</span><span class="s">'fold0'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'fold0'</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="s">'int'</span><span class="p">)</span>
<span class="n">gc</span><span class="p">.</span><span class="n">collect</span><span class="p">()</span>

<span class="n">train</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'fold0'</span><span class="p">])[</span><span class="s">'Pawpularity'</span><span class="p">].</span><span class="n">agg</span><span class="p">([</span><span class="s">'mean'</span><span class="p">,</span><span class="s">'std'</span><span class="p">,</span><span class="s">'count'</span><span class="p">])</span>
</code></pre></div></div>

<h2 id="bins-열">bins 열</h2>

<p>pawpularity의 정답라벨을 20개로 맞춰주기 위함 (1-100 까지의 정답라벨 존재, //5 하면 20개로 나뉘어짐)</p>

<h2 id="stratifiedkfold-1">StratifiedKFold</h2>

<ul>
  <li>
    <p>불균형한 dataset일 경우 사용하는 kfold 방법</p>
  </li>
  <li>
    <p>k개의 fold를 분할한 이후에도 전체 훈련 데이터의 class 비율과 각 fold가 가지고 있는 class 비율을 맞춰줍니다.</p>
  </li>
</ul>

<h2 id="enumerate문">enumerate문</h2>

<p>나도 모르겠음.</p>

<h2 id="astype">astype</h2>

<p>train[‘fold0’] 컬럼을 int형으로 변환</p>

<h2 id="groupby">groupby</h2>

<p><code class="language-plaintext highlighter-rouge">train.groupby(['fold0'])['Pawpularity'].agg(['mean','std','count'])</code></p>

<p>fold마다 pawpularity의 mean(평균), std(표준편차), count(개수)값을 나타내줍니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">modelpath</span> <span class="o">=</span> <span class="p">{</span> <span class="n">m</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">'/'</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">split</span><span class="p">(</span><span class="s">'.'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="p">:</span><span class="n">m</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">glob</span><span class="p">(</span><span class="s">'../input/pytorch-pretrained-0/*.pt'</span><span class="p">)</span><span class="o">+</span><span class="n">glob</span><span class="p">(</span><span class="s">'../input/pytorch-pretrained-1/*.pt'</span><span class="p">)</span><span class="o">+</span><span class="n">glob</span><span class="p">(</span><span class="s">'../input/pytorch-pretrained-2/*.pt'</span><span class="p">)</span><span class="o">+</span><span class="n">glob</span><span class="p">(</span><span class="s">'../input/pytorch-pretrained-3/*.pt'</span><span class="p">)}</span>
<span class="n">modelpath</span>

</code></pre></div></div>

<h2 id="예시">예시</h2>

<ul>
  <li>str = ../input/pytorch-pretrained-0/resnetv2_101x1_bitm.pt 일때,</li>
</ul>

<p>str.split(‘/’) 의 결과</p>

<blockquote>
  <p>../input/pytorch-pretrained-0/resnetv2_101x1_bitm.pt</p>
</blockquote>

<p>str.split(‘/’)[-1] 의 결과</p>

<blockquote>
  <p>[’..’, ‘input’, ‘pytorch-pretrained-0’, ‘resnetv2_101x1_bitm.pt’]</p>
</blockquote>

<p>str.split(‘/’)[-1].split(‘.’)의 결과</p>

<blockquote>
  <p>[‘resnetv2_101x1_bitm’, ‘pt’]</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># EMB TEST가 뭘까
</span><span class="n">EMB_TEST</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">arch</span> <span class="ow">in</span> <span class="n">names</span><span class="p">:</span>
    <span class="n">starttime</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">timm</span><span class="p">.</span><span class="n">create_model</span><span class="p">(</span><span class="n">arch</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="s">'cuda'</span><span class="p">)</span>
    <span class="n">model</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">modelpath</span><span class="p">[</span><span class="n">arch</span><span class="p">]))</span>
    <span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>

    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">PawpularDataset</span><span class="p">(</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">test</span><span class="p">.</span><span class="n">Id</span><span class="p">.</span><span class="n">values</span><span class="p">,</span>
        <span class="n">base_path</span><span class="o">=</span><span class="s">'../input/petfinder-pawpularity-score/test/'</span><span class="p">,</span>
        <span class="n">modelcfg</span> <span class="o">=</span> <span class="n">resolve_data_config</span><span class="p">({},</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">),</span>
        <span class="n">aug</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">BS</span> <span class="o">=</span> <span class="mi">10</span> <span class="k">if</span> <span class="n">arch</span> <span class="ow">in</span> <span class="p">[</span><span class="s">'tf_efficientnet_l2_ns'</span><span class="p">]</span> <span class="k">else</span> <span class="mi">16</span>
    <span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">res</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="p">(</span><span class="n">img</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="s">'cuda'</span><span class="p">)).</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">train_dataloader</span><span class="p">]</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">EMB_TEST</span><span class="p">[</span><span class="n">arch</span><span class="p">]</span> <span class="o">=</span> <span class="n">res</span>
    
    <span class="k">print</span><span class="p">(</span> <span class="n">arch</span><span class="p">,</span> <span class="s">', Done in:'</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">starttime</span><span class="p">),</span> <span class="s">'s'</span> <span class="p">)</span>
    
    <span class="k">del</span> <span class="n">model</span><span class="p">,</span> <span class="n">res</span>
    <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">empty_cache</span><span class="p">()</span> <span class="c1"># PyTorch thing to clean RAM
</span>    <span class="n">gc</span><span class="p">.</span><span class="n">collect</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="p">)</span>    
<span class="nb">len</span><span class="p">(</span><span class="n">EMB_TEST</span><span class="p">),</span> <span class="n">EMB_TEST</span><span class="p">.</span><span class="n">keys</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="timmcreate_modelarch-pretrainedfalsetocuda">timm.create_model(arch, pretrained=False).to(‘cuda’)</h2>

<ul>
  <li>
    <p>timm.create_model</p>

    <blockquote>
      <p><code class="language-plaintext highlighter-rouge">timm</code> is a deep-learning library created by <a href="https://twitter.com/wightmanr">Ross Wightman</a> and is a collection of SOTA computer vision models, layers, utilities, optimizers, schedulers, data-loaders, augmentations and also training/validating scripts with ability to reproduce ImageNet training results.</p>
    </blockquote>

    <p>https://fastai.github.io/timmdocs/</p>

    <p>pretrained=false인 상태로 names의 객체들을 불러와 모델을 생성해줍니다. gpu를 사용할 수 있도록 <code class="language-plaintext highlighter-rouge">.to('cuda')</code>명령어를 사용해 주었습니다.</p>

    <p>그밖의 gpu를 사용할 수있는 명령어는 다음과 같습니다.</p>

    <ul>
      <li>
        <p>x = torch.tensor([1., 2.], device=”cuda”)</p>
      </li>
      <li>
        <p>x = torch.tensor([1., 2.]).cuda()</p>
      </li>
      <li>
        <p>https://y-rok.github.io/pytorch/2020/10/03/pytorch-gpu.html</p>
      </li>
    </ul>
  </li>
</ul>

<h2 id="load_state_dicttorchloadmodelpatharch">load_state_dict(torch.load(modelpath[arch]))</h2>

<ul>
  <li>load_state_dict는 가중치를 불러오는 메소드입니다.</li>
  <li>
    <p>새로운 모델 인스턴스를 생성한 후에 가중치를 불러올 경우, pretrained =False를 주고, load_state_dict메소드를 이용해 가중치 값을불러오게 됩니다.</p>
  </li>
  <li>https://tutorials.pytorch.kr/beginner/basics/saveloadrun_tutorial.html</li>
</ul>

<h2 id="modeleval">model.eval()</h2>

<ul>
  <li>
    <p>추론(inference)을 하기 전에 <code class="language-plaintext highlighter-rouge">model.eval()</code> 메소드를 호출하여 드롭아웃(dropout)과 배치 정규화(batch normalization)를 평가 모드(evaluation mode)로 설정해야 합니다. 그렇지 않으면 일관성 없는 추론 결과가 생성됩니다.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">.eval()</code> 함수는 evaluation 과정에서 사용하지 않아야 하는 layer들을 알아서 off 시키도록 하는 함수이며</p>

    <p>evaluation/validation 과정에선 보통 <code class="language-plaintext highlighter-rouge">model.eval()</code>과 <code class="language-plaintext highlighter-rouge">torch.no_grad()</code>를 함께 사용합니다.</p>
  </li>
  <li>사용 방법 관련 url : https://tutorials.pytorch.kr/beginner/basics/saveloadrun_tutorial.html</li>
  <li>eval 이 무엇인지 : https://stackoverflow.com/questions/60018578/what-does-model-eval-do-in-pytorch/60018731#60018731</li>
  <li>eval 이 무엇인지 : https://bluehorn07.github.io/2021/02/27/model-eval-and-train.html</li>
</ul>

<h2 id="dataloadertrain_dataset-batch_sizebs-num_workers-2-shufflefalse">DataLoader(train_dataset, batch_size=BS, num_workers= 2, shuffle=False)</h2>

<ul>
  <li>
    <p>dataloader는 기본적으로 단일 프로세스 데이터 로드를 사용합니다. num_workers 에 양의 정수를 설정하게되면, 지정된 수의 로더 작업자 프로세스로 멀티 프로세스 데이터 로드가 켜집니다.</p>
  </li>
  <li>
    <p>https://tutorials.pytorch.kr/beginner/basics/data_tutorial.html</p>
  </li>
</ul>

<h2 id="with-torchno_grad">with torch.no_grad():</h2>

<ul>
  <li>
    <p>자원을 획득하고 사용 후 반납해야 하는 경우에 주로 사용합니다.</p>
  </li>
  <li>
    <p>https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&amp;blogId=wideeyed&amp;logNo=221653260516</p>
  </li>
  <li>
    <p><img src="../images/pages/image-20220208130816814.png" alt="image-20220208130816814" /></p>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">PawpularDataset_HFLIP</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">base_path</span><span class="o">=</span><span class="s">'../input/petfinder-pawpularity-score/train/'</span><span class="p">,</span> <span class="n">modelcfg</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">doflip</span><span class="o">=</span><span class="bp">False</span> <span class="p">):</span>
        
        <span class="bp">self</span><span class="p">.</span><span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">base_path</span> <span class="o">=</span> <span class="n">base_path</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">modelcfg</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">doflip</span><span class="o">=</span><span class="n">doflip</span>
        
    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">images</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">base_path</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">images</span><span class="p">[</span><span class="n">item</span><span class="p">]</span> <span class="o">+</span> <span class="s">'.jpg'</span><span class="p">).</span><span class="n">convert</span><span class="p">(</span><span class="s">'RGB'</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">doflip</span><span class="o">==</span><span class="bp">True</span><span class="p">:</span>
            <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">PIL</span><span class="p">.</span><span class="n">Image</span><span class="p">.</span><span class="n">FLIP_LEFT_RIGHT</span><span class="p">)</span>
            <span class="n">width</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="n">img</span><span class="p">.</span><span class="n">size</span>
            <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="p">.</span><span class="n">crop</span><span class="p">((</span><span class="mf">0.0</span><span class="o">*</span><span class="n">width</span><span class="p">,</span> <span class="mf">0.02</span><span class="o">*</span><span class="n">height</span><span class="p">,</span> <span class="mf">0.98</span><span class="o">*</span><span class="n">width</span><span class="p">,</span> <span class="mf">0.98</span> <span class="o">*</span> <span class="n">height</span><span class="p">))</span>  
        
        <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">img</span>


<span class="k">for</span> <span class="n">arch</span> <span class="ow">in</span> <span class="n">names_hflip_crop</span><span class="p">:</span>
    <span class="n">starttime</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>

    <span class="n">archname</span> <span class="o">=</span> <span class="n">arch</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">'_hflip_'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">arch</span> <span class="o">==</span> <span class="s">'tf_efficientnet_l2_ns_512'</span><span class="p">:</span>
        <span class="n">archname</span> <span class="o">=</span> <span class="s">'tf_efficientnet_l2_ns'</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">timm</span><span class="p">.</span><span class="n">create_model</span><span class="p">(</span><span class="n">archname</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="s">'cuda'</span><span class="p">)</span>
    <span class="n">model</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">modelpath</span><span class="p">[</span><span class="n">archname</span><span class="p">]))</span>
    <span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
    
     <span class="c1"># Get model default transforms
</span>    <span class="n">transf</span> <span class="o">=</span> <span class="n">resolve_data_config</span><span class="p">({},</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
    <span class="n">sz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">arch</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">'_'</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">transf</span><span class="p">[</span><span class="s">'input_size'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">sz</span><span class="p">,</span> <span class="n">sz</span><span class="p">)</span>
    <span class="n">transf</span><span class="p">[</span><span class="s">'crop_pct'</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>        
    <span class="n">transf</span> <span class="o">=</span> <span class="n">create_transform</span><span class="p">(</span><span class="o">**</span><span class="n">transf</span><span class="p">)</span>

    <span class="n">doflip</span> <span class="o">=</span> <span class="bp">True</span> <span class="k">if</span> <span class="n">arch</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">'_'</span><span class="p">)[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="s">'hflip'</span> <span class="k">else</span> <span class="bp">False</span>
    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">PawpularDataset_HFLIP</span><span class="p">(</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">test</span><span class="p">.</span><span class="n">Id</span><span class="p">.</span><span class="n">values</span><span class="p">,</span>
        <span class="n">base_path</span><span class="o">=</span><span class="s">'../input/petfinder-pawpularity-score/test/'</span><span class="p">,</span>
        <span class="n">modelcfg</span> <span class="o">=</span> <span class="n">transf</span><span class="p">,</span>
        <span class="n">doflip</span> <span class="o">=</span> <span class="n">doflip</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">BS</span> <span class="o">=</span> <span class="mi">10</span> <span class="k">if</span> <span class="n">archname</span> <span class="ow">in</span> <span class="p">[</span><span class="s">'tf_efficientnet_l2_ns'</span><span class="p">]</span> <span class="k">else</span> <span class="mi">16</span>
    <span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BS</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">res</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="p">(</span><span class="n">img</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="s">'cuda'</span><span class="p">)).</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">train_dataloader</span><span class="p">]</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">EMB_TEST</span><span class="p">[</span><span class="n">arch</span><span class="p">]</span> <span class="o">=</span> <span class="n">res</span>

    <span class="k">print</span><span class="p">(</span> <span class="n">arch</span><span class="p">,</span> <span class="s">'imge size:'</span><span class="p">,</span> <span class="n">sz</span><span class="p">,</span> <span class="s">'Hflip:'</span><span class="p">,</span> <span class="n">doflip</span><span class="p">,</span> <span class="s">',Done in:'</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">starttime</span><span class="p">),</span> <span class="s">'s'</span> <span class="p">)</span>
    
    <span class="k">del</span> <span class="n">model</span><span class="p">,</span> <span class="n">res</span>
    <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">empty_cache</span><span class="p">()</span> <span class="c1"># PyTorch thing to clean RAM
</span>    <span class="n">gc</span><span class="p">.</span><span class="n">collect</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="p">)</span>    
<span class="nb">len</span><span class="p">(</span><span class="n">EMB_TEST</span><span class="p">),</span> <span class="n">EMB_TEST</span><span class="p">.</span><span class="n">keys</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="imgtransposepilimageflip_left_right">img.transpose(PIL.Image.FLIP_LEFT_RIGHT)</h2>

<p>이미지를 가로방향으로 뒤집기</p>

<h2 id="archsplit">arch.split()</h2>

<p><img src="../images/pages/image-20220208140254326.png" alt="image-20220208140254326" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">archname</span> <span class="o">=</span> <span class="n">arch</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">'_hflip_'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">arch</span> <span class="o">==</span> <span class="s">'tf_efficientnet_l2_ns_512'</span><span class="p">:</span>
        <span class="n">archname</span> <span class="o">=</span> <span class="s">'tf_efficientnet_l2_ns'</span>
</code></pre></div></div>

<p>archname에 모델이름만 들어가도록 처리</p>

<h2 id="sz--intarchsplit_-1">sz = int(arch.split(‘_’)[-1])</h2>

<h1 id="새로-알게된-함수">새로 알게된 함수</h1>

<ul>
  <li>
    <p>round()</p>

    <p>반올림 함수입니다.</p>

    <p>import math를 하면 사용할 수 있으며, 숫자데이터.round()형식으로 사용합니다.</p>
  </li>
  <li>
    <p>pandas.astype(‘타입’)</p>

    <p>컬럼의 데이터 타입을 변경</p>
  </li>
</ul>

<h1 id="궁금한-점">궁금한 점</h1>

<ul>
  <li>
    <p>Load Train and Test</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># If its Public LB run, then augment Testset to chack batch size memory consumption.
</span><span class="k">if</span> <span class="n">test</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">&lt;</span><span class="mi">10</span><span class="p">:</span>
    <span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span>
        <span class="n">test</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> 
    <span class="p">])</span>
    <span class="n">test</span> <span class="o">=</span> <span class="n">test</span><span class="p">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div>    </div>

    <p>기본 제공 데이터에서 test 데이터 수가 8개가 있습니다. 코드를 실행하면 test 데이터 수가 10개보다 작기 때문에 test 한세트를 5번 연장 시켜 총 40개의 test셋으로 늘려주었습니다. 하지만 이렇게 해봤자 같은 test데이터이기 때문에 각각 같은 결과가 나올 것 같은데 굳이 왜 이렇게 해주었는지 모르겠습니다.</p>
  </li>
  <li>
    <p>StratifiedKFold</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train</span><span class="p">[</span><span class="s">'bins'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'Pawpularity'</span><span class="p">]</span><span class="o">//</span><span class="mi">5</span><span class="p">).</span><span class="nb">round</span><span class="p">()</span>
  
<span class="n">train</span><span class="p">[</span><span class="s">'fold0'</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="n">skf</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">skf</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">train</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">train</span><span class="p">[</span><span class="s">'bins'</span><span class="p">])):</span>
    <span class="n">train</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
  
<span class="n">train</span><span class="p">[</span><span class="s">'fold0'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'fold0'</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="s">'int'</span><span class="p">)</span>
<span class="n">gc</span><span class="p">.</span><span class="n">collect</span><span class="p">()</span>
  
<span class="n">train</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'fold0'</span><span class="p">])[</span><span class="s">'Pawpularity'</span><span class="p">].</span><span class="n">agg</span><span class="p">([</span><span class="s">'mean'</span><span class="p">,</span><span class="s">'std'</span><span class="p">,</span><span class="s">'count'</span><span class="p">])</span>
</code></pre></div>    </div>

    <p>enumerate부분 잘 몰겠다. 어떤 효과인지 ㅎ_ㅎ</p>
  </li>
</ul>]]></content><author><name>Armando Maynez</name></author><summary type="html"><![CDATA[오늘은 새로 가입한 kaggle 스터디에서 발표준비를 하면서 공부한 내용을 정리해 보았습니다.]]></summary></entry><entry><title type="html">Cs231 5강. cnn</title><link href="http://localhost:4000/CS231-5%EA%B0%95.-CNN.html" rel="alternate" type="text/html" title="Cs231 5강. cnn" /><published>2022-02-08T00:00:00+09:00</published><updated>2022-02-08T00:00:00+09:00</updated><id>http://localhost:4000/CS231%205%EA%B0%95.%20CNN</id><content type="html" xml:base="http://localhost:4000/CS231-5%EA%B0%95.-CNN.html"><![CDATA[<p>Mirror padding</p>

<p>https://joungheekim.github.io/2020/09/28/paper-review/</p>

<p>https://stackoverflow.com/questions/42317238/why-do-we-use-fully-connected-layer-at-the-end-of-cnn</p>

<p><img src="../../../../Typora Images/image-20220124165945525.png" alt="image-20220124165945525" /></p>

<p><img src="../../../../Typora Images/image-20220124170002427.png" alt="image-20220124170002427" /></p>

<p><img src="../../../../Typora Images/image-20220124170017608.png" alt="image-20220124170017608" /></p>

<p>https://www.cs.ryerson.ca/~aharley/vis/conv/</p>]]></content><author><name>Armando Maynez</name></author><summary type="html"><![CDATA[Mirror padding]]></summary></entry><entry><title type="html">Alexnet이란</title><link href="http://localhost:4000/AlexNet%EC%9D%B4%EB%9E%80.html" rel="alternate" type="text/html" title="Alexnet이란" /><published>2022-02-08T00:00:00+09:00</published><updated>2022-02-08T00:00:00+09:00</updated><id>http://localhost:4000/AlexNet%EC%9D%B4%EB%9E%80</id><content type="html" xml:base="http://localhost:4000/AlexNet%EC%9D%B4%EB%9E%80.html"><![CDATA[<p>오늘은 AlexNet에 대해서 정리해보겠습니다.</p>

<p>참고한 자료는 다음과 같습니다.</p>

<ul>
  <li>chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/viewer.html?pdfurl=https%3A%2F%2Fproceedings.neurips.cc%2Fpaper%2F2012%2Ffile%2Fc399862d3b9d6b76c8436e924a68c45b-Paper.pdf&amp;clen=1418820</li>
  <li>https://bskyvision.com/421</li>
</ul>

<hr />

<h1 id="1-alexnet이란">1. AlexNet이란?</h1>

<p>2012년 Image Classification Task에서 Geoffrey Hinton 교수님이 이끄는 토론토 대학의 SuperVision팀이 오류율 16%로 1등을 달성합니다. 작년의 우승자는 오류율 26%, 제작년은 28%였으니 엄청난 차이를 보여주었습니다.</p>

<p>superVision팀이 사용한 모델이 AlexNet입니다.</p>

<p><img src="../images/pages/99FEB93C5C80B5192E" alt="img" /></p>

<h2 id="alexnet의-구조">AlexNet의 구조</h2>

<p>기본 구조는 <a href="https://bskyvision.com/418">LeNet-5</a>와 크게 다르지 않습니다. 2개의  GPU로 병렬연산을 수행하기 위해 병렬 구조로 설계되었다는 점이 가장 큰 변화입니다.</p>

<p>총 8개의 레이어로 이루어져 있으며, 5개는 Conv 레이어, 3개는 FC 레이어로 구성되어 있습니다. (맨 왼쪽은 input data입니다.)</p>

<p>2, 4, 5번째 컨볼루션 레이어들은 전 단계의 feature map과 연결되어 있지만, 3번째 레이어에서는 병렬처리로 나뉜 두 단계의 feature맵과 모두 연결되어 있는 것이 특징입니다.</p>

<h3 id="input-data">input data</h3>

<p>227 * 227 * 3 의 이미지가 들어옵니다. (그림에선 224라고 되어있는데, 잘못된 것입니다.)</p>

<h3 id="첫번째-conv-층">첫번째 Conv 층</h3>

<p>96개의 11*11*3 사이즈의 필터로 영상을 처리합니다.</p>

<p>stride = 4</p>

<p>zero-padding 사용 X</p>

<p>-&gt; 55*55*96 feature map 생성</p>

<p>Activation func : Relu</p>

<p>Relu 활성화 함수를 지나고 나면, 3*3 overlapping max pooling이 stride 2값으로 시행됩니다.</p>

<p>그 결과 27*27*96 fearture map을 가지게 됩니다.</p>

<p>local response normalization이 시행됩니다. 이는 수렴 속도를 가속화 해준다고 합니다.</p>

<p>또한, 특성맵의 차원을 변화시키지 않아 27*27*96의 feature map이 유지된다고 합니다.</p>]]></content><author><name>Armando Maynez</name></author><summary type="html"><![CDATA[오늘은 AlexNet에 대해서 정리해보겠습니다.]]></summary></entry></feed>